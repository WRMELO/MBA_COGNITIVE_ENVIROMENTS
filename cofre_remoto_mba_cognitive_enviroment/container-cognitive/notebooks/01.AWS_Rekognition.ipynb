{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "497ea0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cliente AWS Rekognition configurado com sucesso!\n",
      "ğŸ”— ConexÃ£o com Rekognition estabelecida. Collections disponÃ­veis: 0\n",
      "ğŸ“¦ FunÃ§Ã£o detect_faces_in_image() definida com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# CÃ©lula 6: ConfiguraÃ§Ã£o do AWS Rekognition\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "\n",
    "# Configurar cliente Rekognition\n",
    "try:\n",
    "    rekognition_client = boto3.client('rekognition', region_name='us-east-1')\n",
    "    print(\"âœ… Cliente AWS Rekognition configurado com sucesso!\")\n",
    "    \n",
    "    # Teste de conectividade\n",
    "    response = rekognition_client.list_collections()\n",
    "    print(f\"ğŸ”— ConexÃ£o com Rekognition estabelecida. Collections disponÃ­veis: {len(response.get('CollectionIds', []))}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro ao configurar Rekognition: {e}\")\n",
    "\n",
    "def detect_faces_in_image(bucket_name, image_key):\n",
    "    \"\"\"\n",
    "    Detecta faces em imagem armazenada no S3\n",
    "    \n",
    "    Args:\n",
    "        bucket_name (str): Nome do bucket S3\n",
    "        image_key (str): Chave/nome do arquivo no S3\n",
    "    \n",
    "    Returns:\n",
    "        list: Lista de detalhes das faces detectadas\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = rekognition_client.detect_faces(\n",
    "            Image={\n",
    "                'S3Object': {\n",
    "                    'Bucket': bucket_name,\n",
    "                    'Name': image_key\n",
    "                }\n",
    "            },\n",
    "            Attributes=['ALL']  # Retorna todos os atributos faciais\n",
    "        )\n",
    "        \n",
    "        faces = response['FaceDetails']\n",
    "        print(f\"ğŸ¯ {len(faces)} face(s) detectada(s) na imagem '{image_key}'\")\n",
    "        \n",
    "        return faces\n",
    "        \n",
    "    except ClientError as e:\n",
    "        print(f\"âŒ Erro do AWS Rekognition: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erro geral na detecÃ§Ã£o: {e}\")\n",
    "        return []\n",
    "\n",
    "print(\"ğŸ“¦ FunÃ§Ã£o detect_faces_in_image() definida com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3e3a994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Instalando opencv-python...\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… opencv-python instalado com sucesso!\n",
      "ğŸ“¦ Instalando Pillow...\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/site-packages (11.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pillow instalado com sucesso!\n",
      "ğŸ“¦ Instalando matplotlib...\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.58.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… matplotlib instalado com sucesso!\n",
      "ğŸ“¦ Instalando numpy...\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (1.26.4)\n",
      "âœ… numpy instalado com sucesso!\n",
      "\n",
      "ğŸ‰ InstalaÃ§Ã£o concluÃ­da! Reinicie o kernel do Jupyter e execute novamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# CÃ©lula 6.1: InstalaÃ§Ã£o das dependÃªncias necessÃ¡rias\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_packages():\n",
    "    \"\"\"Instala pacotes necessÃ¡rios para processamento de imagem\"\"\"\n",
    "    packages = [\n",
    "        'opencv-python',\n",
    "        'Pillow',\n",
    "        'matplotlib',\n",
    "        'numpy'\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        print(f\"ğŸ“¦ Instalando {package}...\")\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "            print(f\"âœ… {package} instalado com sucesso!\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"âŒ Erro ao instalar {package}: {e}\")\n",
    "\n",
    "# Executar instalaÃ§Ã£o\n",
    "install_packages()\n",
    "\n",
    "print(\"\\nğŸ‰ InstalaÃ§Ã£o concluÃ­da! Reinicie o kernel do Jupyter e execute novamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6680e638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ FunÃ§Ãµes de prÃ©-processamento definidas!\n"
     ]
    }
   ],
   "source": [
    "# CÃ©lula 6.1: PrÃ©-processamento da Imagem\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_document_image(image_path):\n",
    "    \"\"\"\n",
    "    PrÃ©-processa imagem de documento para melhor OCR e detecÃ§Ã£o\n",
    "    \"\"\"\n",
    "    # Carregar imagem\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # 1. Converter para RGB\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # 2. Aumentar contraste para melhor OCR\n",
    "    lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    l = clahe.apply(l)\n",
    "    enhanced = cv2.merge([l, a, b])\n",
    "    enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2RGB)\n",
    "    \n",
    "    # 3. Redimensionar se muito grande (AWS tem limites)\n",
    "    height, width = enhanced.shape[:2]\n",
    "    if width > 4096 or height > 4096:\n",
    "        scale = min(4096/width, 4096/height)\n",
    "        new_width = int(width * scale)\n",
    "        new_height = int(height * scale)\n",
    "        enhanced = cv2.resize(enhanced, (new_width, new_height), interpolation=cv2.INTER_LANCZOS4)\n",
    "    \n",
    "    return enhanced\n",
    "\n",
    "def save_processed_image(processed_img, output_path):\n",
    "    \"\"\"Salva imagem processada\"\"\"\n",
    "    pil_img = Image.fromarray(processed_img)\n",
    "    pil_img.save(output_path, 'JPEG', quality=95)\n",
    "    return output_path\n",
    "\n",
    "print(\"ğŸ“¦ FunÃ§Ãµes de prÃ©-processamento definidas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edca9511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cliente S3 reconfigurado!\n",
      "âœ… Bucket 'staging-face-text' acessÃ­vel!\n",
      "âœ… Cliente Rekognition reconfigurado!\n",
      "ğŸ“¦ Sistema completo configurado com sucesso!\n",
      "ğŸš€ Pronto para processar sua imagem!\n"
     ]
    }
   ],
   "source": [
    "# CÃ©lula 7 CORRIGIDA: Sistema completo com todas as importaÃ§Ãµes\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import os\n",
    "from pathlib import Path\n",
    "import mimetypes\n",
    "import json\n",
    "\n",
    "# Reconfigurar clientes AWS (caso tenham sido perdidos)\n",
    "try:\n",
    "    # Cliente S3\n",
    "    s3_client = boto3.client('s3', region_name='us-east-1')\n",
    "    print(\"âœ… Cliente S3 reconfigurado!\")\n",
    "    \n",
    "    # Verificar se bucket existe\n",
    "    bucket_name = 'staging-face-text'\n",
    "    s3_client.head_bucket(Bucket=bucket_name)\n",
    "    print(f\"âœ… Bucket '{bucket_name}' acessÃ­vel!\")\n",
    "    \n",
    "    # Cliente Rekognition (reconfirmar)\n",
    "    rekognition_client = boto3.client('rekognition', region_name='us-east-1')\n",
    "    print(\"âœ… Cliente Rekognition reconfigurado!\")\n",
    "    \n",
    "except ClientError as e:\n",
    "    print(f\"âŒ Erro de configuraÃ§Ã£o AWS: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro geral: {e}\")\n",
    "\n",
    "def upload_image_to_s3(file_path, bucket_name, object_key=None):\n",
    "    \"\"\"\n",
    "    Upload de imagem para S3 com validaÃ§Ã£o completa\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validar se arquivo existe\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"âŒ Arquivo nÃ£o encontrado: {file_path}\")\n",
    "            return False, None\n",
    "        \n",
    "        # Validar tipo de arquivo\n",
    "        mime_type, _ = mimetypes.guess_type(file_path)\n",
    "        if not mime_type or not mime_type.startswith('image/'):\n",
    "            print(f\"âŒ Arquivo nÃ£o Ã© uma imagem vÃ¡lida: {mime_type}\")\n",
    "            return False, None\n",
    "        \n",
    "        # Definir object_key se nÃ£o fornecido\n",
    "        if object_key is None:\n",
    "            object_key = Path(file_path).name\n",
    "        \n",
    "        # Upload para S3\n",
    "        s3_client.upload_file(\n",
    "            file_path, \n",
    "            bucket_name, \n",
    "            object_key,\n",
    "            ExtraArgs={\n",
    "                'ContentType': mime_type,\n",
    "                'Metadata': {\n",
    "                    'uploaded-by': 'face-text-detector',\n",
    "                    'original-name': Path(file_path).name\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Upload concluÃ­do!\")\n",
    "        print(f\"   ğŸ“ Arquivo local: {file_path}\")\n",
    "        print(f\"   â˜ï¸  S3 Object: s3://{bucket_name}/{object_key}\")\n",
    "        \n",
    "        return True, object_key\n",
    "        \n",
    "    except ClientError as e:\n",
    "        print(f\"âŒ Erro AWS S3: {e}\")\n",
    "        return False, None\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erro no upload: {e}\")\n",
    "        return False, None\n",
    "\n",
    "def list_bucket_contents(bucket_name):\n",
    "    \"\"\"Lista conteÃºdo do bucket S3\"\"\"\n",
    "    try:\n",
    "        response = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "        if 'Contents' in response:\n",
    "            print(f\"ğŸ“‚ ConteÃºdo do bucket '{bucket_name}':\")\n",
    "            for obj in response['Contents']:\n",
    "                print(f\"   ğŸ“„ {obj['Key']} ({obj['Size']} bytes)\")\n",
    "        else:\n",
    "            print(f\"ğŸ“‚ Bucket '{bucket_name}' estÃ¡ vazio\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erro ao listar bucket: {e}\")\n",
    "\n",
    "# Importar funÃ§Ãµes de prÃ©-processamento (caso necessÃ¡rio)\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_document_image(image_path):\n",
    "    \"\"\"PrÃ©-processa imagem de documento para melhor OCR e detecÃ§Ã£o\"\"\"\n",
    "    try:\n",
    "        # Carregar imagem\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"âŒ NÃ£o foi possÃ­vel carregar a imagem: {image_path}\")\n",
    "            return None\n",
    "        \n",
    "        # Converter para RGB\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Aumentar contraste para melhor OCR\n",
    "        lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        l = clahe.apply(l)\n",
    "        enhanced = cv2.merge([l, a, b])\n",
    "        enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2RGB)\n",
    "        \n",
    "        # Redimensionar se muito grande (AWS tem limites)\n",
    "        height, width = enhanced.shape[:2]\n",
    "        if width > 4096 or height > 4096:\n",
    "            scale = min(4096/width, 4096/height)\n",
    "            new_width = int(width * scale)\n",
    "            new_height = int(height * scale)\n",
    "            enhanced = cv2.resize(enhanced, (new_width, new_height), interpolation=cv2.INTER_LANCZOS4)\n",
    "            print(f\"ğŸ“ Imagem redimensionada: {width}x{height} â†’ {new_width}x{new_height}\")\n",
    "        \n",
    "        return enhanced\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erro no prÃ©-processamento: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_processed_image(processed_img, output_path):\n",
    "    \"\"\"Salva imagem processada\"\"\"\n",
    "    try:\n",
    "        pil_img = Image.fromarray(processed_img)\n",
    "        pil_img.save(output_path, 'JPEG', quality=95)\n",
    "        print(f\"ğŸ’¾ Imagem salva: {output_path}\")\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erro ao salvar imagem: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_your_infographic():\n",
    "    \"\"\"Processa especificamente sua imagem de infogrÃ¡fico\"\"\"\n",
    "    \n",
    "    # Localizar imagens no diretÃ³rio atual\n",
    "    current_dir = os.getcwd()\n",
    "    print(f\"ğŸ“ Procurando imagens em: {current_dir}\")\n",
    "    \n",
    "    # Listar arquivos de imagem\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']\n",
    "    found_images = []\n",
    "    \n",
    "    for file in os.listdir(current_dir):\n",
    "        if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "            found_images.append(file)\n",
    "    \n",
    "    if found_images:\n",
    "        print(f\"ğŸ“¸ Imagens encontradas:\")\n",
    "        for i, img in enumerate(found_images, 1):\n",
    "            print(f\"   {i}. {img}\")\n",
    "        \n",
    "        # Usar a primeira imagem encontrada\n",
    "        target_image = found_images[0]\n",
    "        print(f\"\\nğŸ¯ Processando: {target_image}\")\n",
    "        \n",
    "        # PrÃ©-processar a imagem\n",
    "        print(\"ğŸ”§ Aplicando prÃ©-processamento...\")\n",
    "        processed_img = preprocess_document_image(target_image)\n",
    "        \n",
    "        if processed_img is not None:\n",
    "            # Salvar versÃ£o processada\n",
    "            processed_filename = f\"processed_{target_image}\"\n",
    "            processed_path = save_processed_image(processed_img, processed_filename)\n",
    "            \n",
    "            if processed_path:\n",
    "                # Fazer upload da versÃ£o processada\n",
    "                print(\"â˜ï¸ Fazendo upload para S3...\")\n",
    "                success, s3_key = upload_image_to_s3(processed_path, 'staging-face-text')\n",
    "                \n",
    "                if success:\n",
    "                    return processed_path, s3_key\n",
    "                else:\n",
    "                    return None, None\n",
    "            else:\n",
    "                return None, None\n",
    "        else:\n",
    "            print(\"âŒ Falha no prÃ©-processamento\")\n",
    "            return None, None\n",
    "    else:\n",
    "        print(\"âŒ Nenhuma imagem encontrada no diretÃ³rio atual\")\n",
    "        print(\"ğŸ’¡ Coloque sua imagem na pasta do projeto e execute novamente\")\n",
    "        return None, None\n",
    "\n",
    "print(\"ğŸ“¦ Sistema completo configurado com sucesso!\")\n",
    "print(\"ğŸš€ Pronto para processar sua imagem!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5f16a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Iniciando processamento da sua imagem...\n",
      "ğŸ“ Procurando imagens em: /app\n",
      "ğŸ“¸ Imagens encontradas:\n",
      "   1. Pasted image 20250608090919.png\n",
      "   2. processed_Pasted image 20250608090919.png\n",
      "\n",
      "ğŸ¯ Processando: Pasted image 20250608090919.png\n",
      "ğŸ”§ Aplicando prÃ©-processamento...\n",
      "ğŸ’¾ Imagem salva: processed_Pasted image 20250608090919.png\n",
      "â˜ï¸ Fazendo upload para S3...\n",
      "âœ… Upload concluÃ­do!\n",
      "   ğŸ“ Arquivo local: processed_Pasted image 20250608090919.png\n",
      "   â˜ï¸  S3 Object: s3://staging-face-text/processed_Pasted image 20250608090919.png\n",
      "\n",
      "ğŸ‰ SUCESSO!\n",
      "ğŸ“ Arquivo local processado: processed_Pasted image 20250608090919.png\n",
      "â˜ï¸  Arquivo no S3: processed_Pasted image 20250608090919.png\n",
      "ğŸš€ Pronto para detecÃ§Ã£o facial e OCR!\n",
      "\n",
      "ğŸ“‚ Verificando bucket:\n",
      "ğŸ“‚ ConteÃºdo do bucket 'staging-face-text':\n",
      "   ğŸ“„ processed_Pasted image 20250608090919.png (136758 bytes)\n"
     ]
    }
   ],
   "source": [
    "# Teste completo\n",
    "print(\"ğŸ§ª Iniciando processamento da sua imagem...\")\n",
    "processed_path, s3_key = process_your_infographic()\n",
    "\n",
    "if s3_key:\n",
    "    print(f\"\\nğŸ‰ SUCESSO!\")\n",
    "    print(f\"ğŸ“ Arquivo local processado: {processed_path}\")\n",
    "    print(f\"â˜ï¸  Arquivo no S3: {s3_key}\")\n",
    "    print(\"ğŸš€ Pronto para detecÃ§Ã£o facial e OCR!\")\n",
    "    \n",
    "    # Listar conteÃºdo do bucket\n",
    "    print(\"\\nğŸ“‚ Verificando bucket:\")\n",
    "    list_bucket_contents('staging-face-text')\n",
    "else:\n",
    "    print(\"âŒ Falha no processamento. Verifique se hÃ¡ imagens na pasta.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1af85c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cliente AWS Textract configurado com sucesso!\n",
      "ğŸ“¦ Sistema de OCR configurado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# CÃ©lula 8 CORRIGIDA: Sistema completo de OCR com AWS Textract\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Configurar cliente Textract\n",
    "try:\n",
    "    textract_client = boto3.client('textract', region_name='us-east-1')\n",
    "    print(\"âœ… Cliente AWS Textract configurado com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro ao configurar Textract: {e}\")\n",
    "\n",
    "def extract_text_from_s3_image(bucket_name, image_key):\n",
    "    \"\"\"\n",
    "    Extrai todo o texto de uma imagem no S3 usando AWS Textract\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"ğŸ” Iniciando OCR da imagem: {image_key}\")\n",
    "        \n",
    "        # Executar OCR com Textract\n",
    "        response = textract_client.detect_document_text(\n",
    "            Document={\n",
    "                'S3Object': {\n",
    "                    'Bucket': bucket_name,\n",
    "                    'Name': image_key\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Processar resultados\n",
    "        extracted_text = \"\"\n",
    "        text_blocks = []\n",
    "        words = []\n",
    "        lines = []\n",
    "        \n",
    "        for block in response['Blocks']:\n",
    "            if block['BlockType'] == 'LINE':\n",
    "                line_text = block['Text']\n",
    "                extracted_text += line_text + \"\\n\"\n",
    "                lines.append({\n",
    "                    'text': line_text,\n",
    "                    'confidence': round(block['Confidence'], 2),\n",
    "                    'bounding_box': block['Geometry']['BoundingBox']\n",
    "                })\n",
    "            \n",
    "            elif block['BlockType'] == 'WORD':\n",
    "                words.append({\n",
    "                    'text': block['Text'],\n",
    "                    'confidence': round(block['Confidence'], 2),\n",
    "                    'bounding_box': block['Geometry']['BoundingBox']\n",
    "                })\n",
    "        \n",
    "        # Compilar resultados\n",
    "        result = {\n",
    "            'image_key': image_key,\n",
    "            'bucket_name': bucket_name,\n",
    "            'full_text': extracted_text.strip(),\n",
    "            'total_lines': len(lines),\n",
    "            'total_words': len(words),\n",
    "            'lines': lines,\n",
    "            'words': words,\n",
    "            'extraction_timestamp': datetime.now().isoformat(),\n",
    "            'aws_response_metadata': response.get('ResponseMetadata', {})\n",
    "        }\n",
    "        \n",
    "        # EstatÃ­sticas de confianÃ§a\n",
    "        if words:\n",
    "            confidences = [word['confidence'] for word in words]\n",
    "            result['confidence_stats'] = {\n",
    "                'average': round(sum(confidences) / len(confidences), 2),\n",
    "                'min': min(confidences),\n",
    "                'max': max(confidences)\n",
    "            }\n",
    "        \n",
    "        print(f\"ğŸ“Š OCR CONCLUÃDO!\")\n",
    "        print(f\"   ğŸ“ Linhas de texto: {len(lines)}\")\n",
    "        print(f\"   ğŸ”¤ Palavras detectadas: {len(words)}\")\n",
    "        print(f\"   ğŸ¯ ConfianÃ§a mÃ©dia: {result.get('confidence_stats', {}).get('average', 'N/A')}%\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except ClientError as e:\n",
    "        print(f\"âŒ Erro do AWS Textract: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erro na extraÃ§Ã£o de texto: {e}\")\n",
    "        return None\n",
    "\n",
    "def display_ocr_results(ocr_result):\n",
    "    \"\"\"Exibe resultados do OCR de forma organizada\"\"\"\n",
    "    if not ocr_result:\n",
    "        print(\"âŒ Nenhum resultado de OCR para exibir\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“„ RESULTADOS DO OCR (TEXTRACT)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"ğŸ“¸ Imagem: {ocr_result['image_key']}\")\n",
    "    print(f\"ğŸ• Processado em: {ocr_result['extraction_timestamp']}\")\n",
    "    print(f\"ğŸ“Š EstatÃ­sticas:\")\n",
    "    print(f\"   â€¢ Linhas: {ocr_result['total_lines']}\")\n",
    "    print(f\"   â€¢ Palavras: {ocr_result['total_words']}\")\n",
    "    \n",
    "    if 'confidence_stats' in ocr_result:\n",
    "        stats = ocr_result['confidence_stats']\n",
    "        print(f\"   â€¢ ConfianÃ§a: {stats['average']}% (min: {stats['min']}%, max: {stats['max']}%)\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ TEXTO EXTRAÃDO:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(ocr_result['full_text'])\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Mostrar linhas com baixa confianÃ§a (CORRIGIDO)\n",
    "    low_confidence_lines = [line for line in ocr_result['lines'] if line['confidence'] < 80]\n",
    "    if low_confidence_lines:\n",
    "        print(f\"\\nâš ï¸  LINHAS COM BAIXA CONFIANÃ‡A (<80%):\")\n",
    "        for line in low_confidence_lines:\n",
    "            print(f\"   â€¢ '{line['text']}' (confianÃ§a: {line['confidence']}%)\")\n",
    "\n",
    "def save_ocr_results_to_s3(ocr_result, bucket_name):\n",
    "    \"\"\"Salva resultados do OCR no S3\"\"\"\n",
    "    try:\n",
    "        # Nome do arquivo de resultados\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        results_key = f\"ocr_results_{timestamp}.json\"\n",
    "        \n",
    "        # Salvar no S3\n",
    "        s3_client.put_object(\n",
    "            Bucket=bucket_name,\n",
    "            Key=results_key,\n",
    "            Body=json.dumps(ocr_result, indent=2, ensure_ascii=False),\n",
    "            ContentType='application/json',\n",
    "            Metadata={\n",
    "                'content-type': 'ocr-results',\n",
    "                'source-image': ocr_result['image_key']\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(f\"ğŸ’¾ Resultados salvos: s3://{bucket_name}/{results_key}\")\n",
    "        return results_key\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erro ao salvar resultados: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"ğŸ“¦ Sistema de OCR configurado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7020cd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Executando OCR na sua imagem...\n",
      "ğŸ” Iniciando OCR da imagem: processed_Pasted image 20250608090919.png\n",
      "ğŸ“Š OCR CONCLUÃDO!\n",
      "   ğŸ“ Linhas de texto: 36\n",
      "   ğŸ”¤ Palavras detectadas: 143\n",
      "   ğŸ¯ ConfianÃ§a mÃ©dia: 84.13%\n",
      "\n",
      "============================================================\n",
      "ğŸ“„ RESULTADOS DO OCR (TEXTRACT)\n",
      "============================================================\n",
      "ğŸ“¸ Imagem: processed_Pasted image 20250608090919.png\n",
      "ğŸ• Processado em: 2025-06-10T16:09:13.888821\n",
      "ğŸ“Š EstatÃ­sticas:\n",
      "   â€¢ Linhas: 36\n",
      "   â€¢ Palavras: 143\n",
      "   â€¢ ConfianÃ§a: 84.13% (min: 7.03%, max: 99.94%)\n",
      "\n",
      "ğŸ“ TEXTO EXTRAÃDO:\n",
      "----------------------------------------\n",
      "FIAP MBA+\n",
      "FACE & TEXT EXTRACTION\n",
      "o setor de fraudes apontou que existem clientes que se queixaram de nÃ£o contratar serviÃ§os\n",
      "especÃ­ficos, como o crÃ©dito pessoal. Entretanto apÃ³s o indicador de DetecÃ§Ã£o de vivacidade\n",
      "(liveness), desenvolvido na disciplina de Computer Vision, ter apresentado um percentual de\n",
      "vivacidade menor que 90% apontou a necessidade de uma nova validaÃ§Ã£o do self da pessoa com o\n",
      "documento.\n",
      "REPUBLICA FEDERATIVA 00 BRASIL\n",
      "BR\n",
      "SECRETARIA NACIONA TRANSITO\n",
      "CARTERA NACIONAL DE HABULTACIO DRIVER LICENSE PERMISO DE CONDUCCION\n",
      "see\n",
      "det\n",
      "NOME SOCIAL TEST CENTOR DEZ\n",
      "16090389 SAO PALLOSS\n",
      "-\n",
      "Miss referencia\n",
      "Date\n",
      "- business\n",
      "26060022\n",
      "85 3691-7258\n",
      "JULHO 2022\n",
      "12/07/2022\n",
      "R$\n",
      "101.48\n",
      "503584349\n",
      "000000\n",
      "1195\n",
      "-\n",
      "10\n",
      "PA/DO TERTE HCM 5\n",
      "1. ExtraÃ§Ã£o da Face, Nome e CPF\n",
      "2. ComparaÃ§Ã£o de faces (precisam ter\n",
      "3. ExtraÃ§Ã£o do Nome e EndereÃ§o. Nome\n",
      "mais do 90% de semelhanÃ§a)\n",
      "precisa ser o mesmo da CNH.\n",
      "----------------------------------------\n",
      "\n",
      "âš ï¸  LINHAS COM BAIXA CONFIANÃ‡A (<80%):\n",
      "   â€¢ 'CARTERA NACIONAL DE HABULTACIO DRIVER LICENSE PERMISO DE CONDUCCION' (confianÃ§a: 69.01%)\n",
      "   â€¢ 'see' (confianÃ§a: 7.03%)\n",
      "   â€¢ 'det' (confianÃ§a: 16.55%)\n",
      "   â€¢ 'NOME SOCIAL TEST CENTOR DEZ' (confianÃ§a: 59.88%)\n",
      "   â€¢ '16090389 SAO PALLOSS' (confianÃ§a: 31.92%)\n",
      "   â€¢ '-' (confianÃ§a: 25.78%)\n",
      "   â€¢ 'Miss referencia' (confianÃ§a: 36.08%)\n",
      "   â€¢ '- business' (confianÃ§a: 30.93%)\n",
      "   â€¢ '26060022' (confianÃ§a: 18.89%)\n",
      "   â€¢ '503584349' (confianÃ§a: 21.69%)\n",
      "   â€¢ '000000' (confianÃ§a: 25.43%)\n",
      "   â€¢ '1195' (confianÃ§a: 17.52%)\n",
      "   â€¢ '-' (confianÃ§a: 31.36%)\n",
      "   â€¢ '10' (confianÃ§a: 76.75%)\n",
      "   â€¢ 'PA/DO TERTE HCM 5' (confianÃ§a: 30.17%)\n",
      "ğŸ’¾ Resultados salvos: s3://staging-face-text/ocr_results_20250610_160913.json\n",
      "\n",
      "ğŸ‰ OCR CONCLUÃDO COM SUCESSO!\n",
      "ğŸ“„ Todo o texto do seu infogrÃ¡fico foi extraÃ­do!\n"
     ]
    }
   ],
   "source": [
    "# Executar OCR na sua imagem processada\n",
    "bucket_name = 'staging-face-text'\n",
    "image_key = 'processed_Pasted image 20250608090919.png'\n",
    "\n",
    "print(\"ğŸ” Executando OCR na sua imagem...\")\n",
    "ocr_results = extract_text_from_s3_image(bucket_name, image_key)\n",
    "\n",
    "if ocr_results:\n",
    "    # Exibir resultados\n",
    "    display_ocr_results(ocr_results)\n",
    "    \n",
    "    # Salvar resultados no S3\n",
    "    results_key = save_ocr_results_to_s3(ocr_results, bucket_name)\n",
    "    \n",
    "    print(f\"\\nğŸ‰ OCR CONCLUÃDO COM SUCESSO!\")\n",
    "    print(f\"ğŸ“„ Todo o texto do seu infogrÃ¡fico foi extraÃ­do!\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Falha na extraÃ§Ã£o de texto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e0b0382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cliente Rekognition reconfigurado!\n",
      "ğŸš€ Executando detecÃ§Ã£o facial na sua imagem...\n",
      "ğŸ‘¥ INICIANDO DETECÃ‡ÃƒO FACIAL\n",
      "==================================================\n",
      "ğŸ” Analisando faces na imagem: processed_Pasted image 20250608090919.png\n",
      "ğŸ¯ 3 face(s) detectada(s) na imagem\n",
      "\n",
      "ğŸ‰ SUCESSO! 3 face(s) detectada(s)\n",
      "==================================================\n",
      "\n",
      "ğŸ‘¤ FACE 1:\n",
      "   ğŸ¯ ConfianÃ§a geral: 100.00%\n",
      "   ğŸ“ PosiÃ§Ã£o: Left=0.498, Top=0.543\n",
      "   ğŸ“ DimensÃµes: Width=0.077, Height=0.172\n",
      "   ğŸ‚ Idade estimada: 18-22 anos\n",
      "   ğŸ‘« GÃªnero: Female (confianÃ§a: 93.2%)\n",
      "   ğŸ˜Š EmoÃ§Ãµes detectadas:\n",
      "      â€¢ CALM: 94.6%\n",
      "      â€¢ HAPPY: 1.1%\n",
      "      â€¢ SURPRISED: 0.1%\n",
      "   ğŸ“¸ Qualidade da imagem:\n",
      "      â€¢ Brilho: 85.7\n",
      "      â€¢ Nitidez: 20.9\n",
      "\n",
      "ğŸ‘¤ FACE 2:\n",
      "   ğŸ¯ ConfianÃ§a geral: 99.99%\n",
      "   ğŸ“ PosiÃ§Ã£o: Left=0.381, Top=0.583\n",
      "   ğŸ“ DimensÃµes: Width=0.045, Height=0.112\n",
      "   ğŸ‚ Idade estimada: 19-23 anos\n",
      "   ğŸ‘« GÃªnero: Female (confianÃ§a: 99.2%)\n",
      "   ğŸ˜Š EmoÃ§Ãµes detectadas:\n",
      "      â€¢ HAPPY: 100.0%\n",
      "      â€¢ SURPRISED: 0.0%\n",
      "      â€¢ CALM: 0.0%\n",
      "   ğŸ“¸ Qualidade da imagem:\n",
      "      â€¢ Brilho: 90.4\n",
      "      â€¢ Nitidez: 7.6\n",
      "   ğŸ‘ï¸  Atributos detectados: Smile (97.9%)\n",
      "\n",
      "ğŸ‘¤ FACE 3:\n",
      "   ğŸ¯ ConfianÃ§a geral: 99.98%\n",
      "   ğŸ“ PosiÃ§Ã£o: Left=0.121, Top=0.665\n",
      "   ğŸ“ DimensÃµes: Width=0.032, Height=0.079\n",
      "   ğŸ‚ Idade estimada: 19-25 anos\n",
      "   ğŸ‘« GÃªnero: Female (confianÃ§a: 99.7%)\n",
      "   ğŸ˜Š EmoÃ§Ãµes detectadas:\n",
      "      â€¢ HAPPY: 100.0%\n",
      "      â€¢ SURPRISED: 0.0%\n",
      "      â€¢ CALM: 0.0%\n",
      "   ğŸ“¸ Qualidade da imagem:\n",
      "      â€¢ Brilho: 88.9\n",
      "      â€¢ Nitidez: 5.8\n",
      "   ğŸ‘ï¸  Atributos detectados: Smile (95.9%)\n",
      "\n",
      "ğŸ“Š ESTATÃSTICAS GERAIS:\n",
      "   ğŸ¯ ConfianÃ§a mÃ©dia: 99.99%\n",
      "   ğŸ“ˆ ConfianÃ§a mÃ¡xima: 100.00%\n",
      "   ğŸ“‰ ConfianÃ§a mÃ­nima: 99.98%\n"
     ]
    }
   ],
   "source": [
    "# CÃ©lula 9 CORRIGIDA: Sistema completo de detecÃ§Ã£o facial\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Reconfigurar cliente Rekognition (caso necessÃ¡rio)\n",
    "try:\n",
    "    rekognition_client = boto3.client('rekognition', region_name='us-east-1')\n",
    "    print(\"âœ… Cliente Rekognition reconfigurado!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro ao configurar Rekognition: {e}\")\n",
    "\n",
    "def detect_faces_in_image(bucket_name, image_key):\n",
    "    \"\"\"\n",
    "    Detecta faces em imagem armazenada no S3\n",
    "    \n",
    "    Args:\n",
    "        bucket_name (str): Nome do bucket S3\n",
    "        image_key (str): Chave/nome do arquivo no S3\n",
    "    \n",
    "    Returns:\n",
    "        list: Lista de detalhes das faces detectadas\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"ğŸ” Analisando faces na imagem: {image_key}\")\n",
    "        \n",
    "        response = rekognition_client.detect_faces(\n",
    "            Image={\n",
    "                'S3Object': {\n",
    "                    'Bucket': bucket_name,\n",
    "                    'Name': image_key\n",
    "                }\n",
    "            },\n",
    "            Attributes=['ALL']  # Retorna todos os atributos faciais\n",
    "        )\n",
    "        \n",
    "        faces = response['FaceDetails']\n",
    "        print(f\"ğŸ¯ {len(faces)} face(s) detectada(s) na imagem\")\n",
    "        \n",
    "        return faces\n",
    "        \n",
    "    except ClientError as e:\n",
    "        print(f\"âŒ Erro do AWS Rekognition: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erro geral na detecÃ§Ã£o: {e}\")\n",
    "        return []\n",
    "\n",
    "def analyze_face_details(face, face_number):\n",
    "    \"\"\"Analisa detalhes de uma face especÃ­fica\"\"\"\n",
    "    print(f\"\\nğŸ‘¤ FACE {face_number}:\")\n",
    "    print(f\"   ğŸ¯ ConfianÃ§a geral: {face['Confidence']:.2f}%\")\n",
    "    \n",
    "    # PosiÃ§Ã£o da face\n",
    "    bbox = face['BoundingBox']\n",
    "    print(f\"   ğŸ“ PosiÃ§Ã£o: Left={bbox['Left']:.3f}, Top={bbox['Top']:.3f}\")\n",
    "    print(f\"   ğŸ“ DimensÃµes: Width={bbox['Width']:.3f}, Height={bbox['Height']:.3f}\")\n",
    "    \n",
    "    # Idade estimada\n",
    "    if 'AgeRange' in face:\n",
    "        age = face['AgeRange']\n",
    "        print(f\"   ğŸ‚ Idade estimada: {age['Low']}-{age['High']} anos\")\n",
    "    \n",
    "    # GÃªnero\n",
    "    if 'Gender' in face:\n",
    "        gender = face['Gender']\n",
    "        print(f\"   ğŸ‘« GÃªnero: {gender['Value']} (confianÃ§a: {gender['Confidence']:.1f}%)\")\n",
    "    \n",
    "    # EmoÃ§Ãµes\n",
    "    if 'Emotions' in face:\n",
    "        emotions = sorted(face['Emotions'], key=lambda x: x['Confidence'], reverse=True)\n",
    "        print(f\"   ğŸ˜Š EmoÃ§Ãµes detectadas:\")\n",
    "        for emotion in emotions[:3]:  # Top 3 emoÃ§Ãµes\n",
    "            print(f\"      â€¢ {emotion['Type']}: {emotion['Confidence']:.1f}%\")\n",
    "    \n",
    "    # Qualidade da imagem\n",
    "    if 'Quality' in face:\n",
    "        quality = face['Quality']\n",
    "        print(f\"   ğŸ“¸ Qualidade da imagem:\")\n",
    "        print(f\"      â€¢ Brilho: {quality['Brightness']:.1f}\")\n",
    "        print(f\"      â€¢ Nitidez: {quality['Sharpness']:.1f}\")\n",
    "    \n",
    "    # Atributos faciais\n",
    "    facial_attributes = ['Smile', 'Eyeglasses', 'Sunglasses', 'Beard', 'Mustache']\n",
    "    detected_attributes = []\n",
    "    \n",
    "    for attr in facial_attributes:\n",
    "        if attr in face and face[attr]['Value']:\n",
    "            confidence = face[attr]['Confidence']\n",
    "            detected_attributes.append(f\"{attr} ({confidence:.1f}%)\")\n",
    "    \n",
    "    if detected_attributes:\n",
    "        print(f\"   ğŸ‘ï¸  Atributos detectados: {', '.join(detected_attributes)}\")\n",
    "\n",
    "def run_face_detection():\n",
    "    \"\"\"Executa detecÃ§Ã£o facial completa na imagem processada\"\"\"\n",
    "    \n",
    "    bucket_name = 'staging-face-text'\n",
    "    image_key = 'processed_Pasted image 20250608090919.png'\n",
    "    \n",
    "    print(\"ğŸ‘¥ INICIANDO DETECÃ‡ÃƒO FACIAL\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Executar detecÃ§Ã£o\n",
    "    faces = detect_faces_in_image(bucket_name, image_key)\n",
    "    \n",
    "    if faces:\n",
    "        print(f\"\\nğŸ‰ SUCESSO! {len(faces)} face(s) detectada(s)\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Analisar cada face detectada\n",
    "        for i, face in enumerate(faces, 1):\n",
    "            analyze_face_details(face, i)\n",
    "        \n",
    "        # EstatÃ­sticas gerais\n",
    "        print(f\"\\nğŸ“Š ESTATÃSTICAS GERAIS:\")\n",
    "        confidences = [face['Confidence'] for face in faces]\n",
    "        print(f\"   ğŸ¯ ConfianÃ§a mÃ©dia: {sum(confidences)/len(confidences):.2f}%\")\n",
    "        print(f\"   ğŸ“ˆ ConfianÃ§a mÃ¡xima: {max(confidences):.2f}%\")\n",
    "        print(f\"   ğŸ“‰ ConfianÃ§a mÃ­nima: {min(confidences):.2f}%\")\n",
    "        \n",
    "        return faces\n",
    "    else:\n",
    "        print(\"âŒ Nenhuma face detectada na imagem\")\n",
    "        print(\"ğŸ’¡ Isso pode acontecer se:\")\n",
    "        print(\"   â€¢ As faces estÃ£o muito pequenas\")\n",
    "        print(\"   â€¢ A qualidade da imagem Ã© baixa\")\n",
    "        print(\"   â€¢ As faces estÃ£o parcialmente ocultas\")\n",
    "        return []\n",
    "\n",
    "# Executar detecÃ§Ã£o facial\n",
    "print(\"ğŸš€ Executando detecÃ§Ã£o facial na sua imagem...\")\n",
    "detected_faces = run_face_detection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
