{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "497ea0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cliente AWS Rekognition configurado com sucesso!\n",
      "🔗 Conexão com Rekognition estabelecida. Collections disponíveis: 0\n",
      "📦 Função detect_faces_in_image() definida com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Célula 6: Configuração do AWS Rekognition\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "\n",
    "# Configurar cliente Rekognition\n",
    "try:\n",
    "    rekognition_client = boto3.client('rekognition', region_name='us-east-1')\n",
    "    print(\"✅ Cliente AWS Rekognition configurado com sucesso!\")\n",
    "    \n",
    "    # Teste de conectividade\n",
    "    response = rekognition_client.list_collections()\n",
    "    print(f\"🔗 Conexão com Rekognition estabelecida. Collections disponíveis: {len(response.get('CollectionIds', []))}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Erro ao configurar Rekognition: {e}\")\n",
    "\n",
    "def detect_faces_in_image(bucket_name, image_key):\n",
    "    \"\"\"\n",
    "    Detecta faces em imagem armazenada no S3\n",
    "    \n",
    "    Args:\n",
    "        bucket_name (str): Nome do bucket S3\n",
    "        image_key (str): Chave/nome do arquivo no S3\n",
    "    \n",
    "    Returns:\n",
    "        list: Lista de detalhes das faces detectadas\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = rekognition_client.detect_faces(\n",
    "            Image={\n",
    "                'S3Object': {\n",
    "                    'Bucket': bucket_name,\n",
    "                    'Name': image_key\n",
    "                }\n",
    "            },\n",
    "            Attributes=['ALL']  # Retorna todos os atributos faciais\n",
    "        )\n",
    "        \n",
    "        faces = response['FaceDetails']\n",
    "        print(f\"🎯 {len(faces)} face(s) detectada(s) na imagem '{image_key}'\")\n",
    "        \n",
    "        return faces\n",
    "        \n",
    "    except ClientError as e:\n",
    "        print(f\"❌ Erro do AWS Rekognition: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro geral na detecção: {e}\")\n",
    "        return []\n",
    "\n",
    "print(\"📦 Função detect_faces_in_image() definida com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3e3a994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Instalando opencv-python...\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ opencv-python instalado com sucesso!\n",
      "📦 Instalando Pillow...\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/site-packages (11.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pillow instalado com sucesso!\n",
      "📦 Instalando matplotlib...\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.58.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ matplotlib instalado com sucesso!\n",
      "📦 Instalando numpy...\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (1.26.4)\n",
      "✅ numpy instalado com sucesso!\n",
      "\n",
      "🎉 Instalação concluída! Reinicie o kernel do Jupyter e execute novamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Célula 6.1: Instalação das dependências necessárias\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_packages():\n",
    "    \"\"\"Instala pacotes necessários para processamento de imagem\"\"\"\n",
    "    packages = [\n",
    "        'opencv-python',\n",
    "        'Pillow',\n",
    "        'matplotlib',\n",
    "        'numpy'\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        print(f\"📦 Instalando {package}...\")\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "            print(f\"✅ {package} instalado com sucesso!\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"❌ Erro ao instalar {package}: {e}\")\n",
    "\n",
    "# Executar instalação\n",
    "install_packages()\n",
    "\n",
    "print(\"\\n🎉 Instalação concluída! Reinicie o kernel do Jupyter e execute novamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6680e638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Funções de pré-processamento definidas!\n"
     ]
    }
   ],
   "source": [
    "# Célula 6.1: Pré-processamento da Imagem\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_document_image(image_path):\n",
    "    \"\"\"\n",
    "    Pré-processa imagem de documento para melhor OCR e detecção\n",
    "    \"\"\"\n",
    "    # Carregar imagem\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # 1. Converter para RGB\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # 2. Aumentar contraste para melhor OCR\n",
    "    lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    l = clahe.apply(l)\n",
    "    enhanced = cv2.merge([l, a, b])\n",
    "    enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2RGB)\n",
    "    \n",
    "    # 3. Redimensionar se muito grande (AWS tem limites)\n",
    "    height, width = enhanced.shape[:2]\n",
    "    if width > 4096 or height > 4096:\n",
    "        scale = min(4096/width, 4096/height)\n",
    "        new_width = int(width * scale)\n",
    "        new_height = int(height * scale)\n",
    "        enhanced = cv2.resize(enhanced, (new_width, new_height), interpolation=cv2.INTER_LANCZOS4)\n",
    "    \n",
    "    return enhanced\n",
    "\n",
    "def save_processed_image(processed_img, output_path):\n",
    "    \"\"\"Salva imagem processada\"\"\"\n",
    "    pil_img = Image.fromarray(processed_img)\n",
    "    pil_img.save(output_path, 'JPEG', quality=95)\n",
    "    return output_path\n",
    "\n",
    "print(\"📦 Funções de pré-processamento definidas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edca9511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cliente S3 reconfigurado!\n",
      "✅ Bucket 'staging-face-text' acessível!\n",
      "✅ Cliente Rekognition reconfigurado!\n",
      "📦 Sistema completo configurado com sucesso!\n",
      "🚀 Pronto para processar sua imagem!\n"
     ]
    }
   ],
   "source": [
    "# Célula 7 CORRIGIDA: Sistema completo com todas as importações\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import os\n",
    "from pathlib import Path\n",
    "import mimetypes\n",
    "import json\n",
    "\n",
    "# Reconfigurar clientes AWS (caso tenham sido perdidos)\n",
    "try:\n",
    "    # Cliente S3\n",
    "    s3_client = boto3.client('s3', region_name='us-east-1')\n",
    "    print(\"✅ Cliente S3 reconfigurado!\")\n",
    "    \n",
    "    # Verificar se bucket existe\n",
    "    bucket_name = 'staging-face-text'\n",
    "    s3_client.head_bucket(Bucket=bucket_name)\n",
    "    print(f\"✅ Bucket '{bucket_name}' acessível!\")\n",
    "    \n",
    "    # Cliente Rekognition (reconfirmar)\n",
    "    rekognition_client = boto3.client('rekognition', region_name='us-east-1')\n",
    "    print(\"✅ Cliente Rekognition reconfigurado!\")\n",
    "    \n",
    "except ClientError as e:\n",
    "    print(f\"❌ Erro de configuração AWS: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erro geral: {e}\")\n",
    "\n",
    "def upload_image_to_s3(file_path, bucket_name, object_key=None):\n",
    "    \"\"\"\n",
    "    Upload de imagem para S3 com validação completa\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validar se arquivo existe\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"❌ Arquivo não encontrado: {file_path}\")\n",
    "            return False, None\n",
    "        \n",
    "        # Validar tipo de arquivo\n",
    "        mime_type, _ = mimetypes.guess_type(file_path)\n",
    "        if not mime_type or not mime_type.startswith('image/'):\n",
    "            print(f\"❌ Arquivo não é uma imagem válida: {mime_type}\")\n",
    "            return False, None\n",
    "        \n",
    "        # Definir object_key se não fornecido\n",
    "        if object_key is None:\n",
    "            object_key = Path(file_path).name\n",
    "        \n",
    "        # Upload para S3\n",
    "        s3_client.upload_file(\n",
    "            file_path, \n",
    "            bucket_name, \n",
    "            object_key,\n",
    "            ExtraArgs={\n",
    "                'ContentType': mime_type,\n",
    "                'Metadata': {\n",
    "                    'uploaded-by': 'face-text-detector',\n",
    "                    'original-name': Path(file_path).name\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ Upload concluído!\")\n",
    "        print(f\"   📁 Arquivo local: {file_path}\")\n",
    "        print(f\"   ☁️  S3 Object: s3://{bucket_name}/{object_key}\")\n",
    "        \n",
    "        return True, object_key\n",
    "        \n",
    "    except ClientError as e:\n",
    "        print(f\"❌ Erro AWS S3: {e}\")\n",
    "        return False, None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro no upload: {e}\")\n",
    "        return False, None\n",
    "\n",
    "def list_bucket_contents(bucket_name):\n",
    "    \"\"\"Lista conteúdo do bucket S3\"\"\"\n",
    "    try:\n",
    "        response = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "        if 'Contents' in response:\n",
    "            print(f\"📂 Conteúdo do bucket '{bucket_name}':\")\n",
    "            for obj in response['Contents']:\n",
    "                print(f\"   📄 {obj['Key']} ({obj['Size']} bytes)\")\n",
    "        else:\n",
    "            print(f\"📂 Bucket '{bucket_name}' está vazio\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro ao listar bucket: {e}\")\n",
    "\n",
    "# Importar funções de pré-processamento (caso necessário)\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_document_image(image_path):\n",
    "    \"\"\"Pré-processa imagem de documento para melhor OCR e detecção\"\"\"\n",
    "    try:\n",
    "        # Carregar imagem\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"❌ Não foi possível carregar a imagem: {image_path}\")\n",
    "            return None\n",
    "        \n",
    "        # Converter para RGB\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Aumentar contraste para melhor OCR\n",
    "        lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        l = clahe.apply(l)\n",
    "        enhanced = cv2.merge([l, a, b])\n",
    "        enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2RGB)\n",
    "        \n",
    "        # Redimensionar se muito grande (AWS tem limites)\n",
    "        height, width = enhanced.shape[:2]\n",
    "        if width > 4096 or height > 4096:\n",
    "            scale = min(4096/width, 4096/height)\n",
    "            new_width = int(width * scale)\n",
    "            new_height = int(height * scale)\n",
    "            enhanced = cv2.resize(enhanced, (new_width, new_height), interpolation=cv2.INTER_LANCZOS4)\n",
    "            print(f\"📏 Imagem redimensionada: {width}x{height} → {new_width}x{new_height}\")\n",
    "        \n",
    "        return enhanced\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro no pré-processamento: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_processed_image(processed_img, output_path):\n",
    "    \"\"\"Salva imagem processada\"\"\"\n",
    "    try:\n",
    "        pil_img = Image.fromarray(processed_img)\n",
    "        pil_img.save(output_path, 'JPEG', quality=95)\n",
    "        print(f\"💾 Imagem salva: {output_path}\")\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro ao salvar imagem: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_your_infographic():\n",
    "    \"\"\"Processa especificamente sua imagem de infográfico\"\"\"\n",
    "    \n",
    "    # Localizar imagens no diretório atual\n",
    "    current_dir = os.getcwd()\n",
    "    print(f\"📁 Procurando imagens em: {current_dir}\")\n",
    "    \n",
    "    # Listar arquivos de imagem\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']\n",
    "    found_images = []\n",
    "    \n",
    "    for file in os.listdir(current_dir):\n",
    "        if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "            found_images.append(file)\n",
    "    \n",
    "    if found_images:\n",
    "        print(f\"📸 Imagens encontradas:\")\n",
    "        for i, img in enumerate(found_images, 1):\n",
    "            print(f\"   {i}. {img}\")\n",
    "        \n",
    "        # Usar a primeira imagem encontrada\n",
    "        target_image = found_images[0]\n",
    "        print(f\"\\n🎯 Processando: {target_image}\")\n",
    "        \n",
    "        # Pré-processar a imagem\n",
    "        print(\"🔧 Aplicando pré-processamento...\")\n",
    "        processed_img = preprocess_document_image(target_image)\n",
    "        \n",
    "        if processed_img is not None:\n",
    "            # Salvar versão processada\n",
    "            processed_filename = f\"processed_{target_image}\"\n",
    "            processed_path = save_processed_image(processed_img, processed_filename)\n",
    "            \n",
    "            if processed_path:\n",
    "                # Fazer upload da versão processada\n",
    "                print(\"☁️ Fazendo upload para S3...\")\n",
    "                success, s3_key = upload_image_to_s3(processed_path, 'staging-face-text')\n",
    "                \n",
    "                if success:\n",
    "                    return processed_path, s3_key\n",
    "                else:\n",
    "                    return None, None\n",
    "            else:\n",
    "                return None, None\n",
    "        else:\n",
    "            print(\"❌ Falha no pré-processamento\")\n",
    "            return None, None\n",
    "    else:\n",
    "        print(\"❌ Nenhuma imagem encontrada no diretório atual\")\n",
    "        print(\"💡 Coloque sua imagem na pasta do projeto e execute novamente\")\n",
    "        return None, None\n",
    "\n",
    "print(\"📦 Sistema completo configurado com sucesso!\")\n",
    "print(\"🚀 Pronto para processar sua imagem!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5f16a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Iniciando processamento da sua imagem...\n",
      "📁 Procurando imagens em: /app\n",
      "📸 Imagens encontradas:\n",
      "   1. Pasted image 20250608090919.png\n",
      "   2. processed_Pasted image 20250608090919.png\n",
      "\n",
      "🎯 Processando: Pasted image 20250608090919.png\n",
      "🔧 Aplicando pré-processamento...\n",
      "💾 Imagem salva: processed_Pasted image 20250608090919.png\n",
      "☁️ Fazendo upload para S3...\n",
      "✅ Upload concluído!\n",
      "   📁 Arquivo local: processed_Pasted image 20250608090919.png\n",
      "   ☁️  S3 Object: s3://staging-face-text/processed_Pasted image 20250608090919.png\n",
      "\n",
      "🎉 SUCESSO!\n",
      "📁 Arquivo local processado: processed_Pasted image 20250608090919.png\n",
      "☁️  Arquivo no S3: processed_Pasted image 20250608090919.png\n",
      "🚀 Pronto para detecção facial e OCR!\n",
      "\n",
      "📂 Verificando bucket:\n",
      "📂 Conteúdo do bucket 'staging-face-text':\n",
      "   📄 processed_Pasted image 20250608090919.png (136758 bytes)\n"
     ]
    }
   ],
   "source": [
    "# Teste completo\n",
    "print(\"🧪 Iniciando processamento da sua imagem...\")\n",
    "processed_path, s3_key = process_your_infographic()\n",
    "\n",
    "if s3_key:\n",
    "    print(f\"\\n🎉 SUCESSO!\")\n",
    "    print(f\"📁 Arquivo local processado: {processed_path}\")\n",
    "    print(f\"☁️  Arquivo no S3: {s3_key}\")\n",
    "    print(\"🚀 Pronto para detecção facial e OCR!\")\n",
    "    \n",
    "    # Listar conteúdo do bucket\n",
    "    print(\"\\n📂 Verificando bucket:\")\n",
    "    list_bucket_contents('staging-face-text')\n",
    "else:\n",
    "    print(\"❌ Falha no processamento. Verifique se há imagens na pasta.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1af85c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cliente AWS Textract configurado com sucesso!\n",
      "📦 Sistema de OCR configurado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Célula 8 CORRIGIDA: Sistema completo de OCR com AWS Textract\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Configurar cliente Textract\n",
    "try:\n",
    "    textract_client = boto3.client('textract', region_name='us-east-1')\n",
    "    print(\"✅ Cliente AWS Textract configurado com sucesso!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Erro ao configurar Textract: {e}\")\n",
    "\n",
    "def extract_text_from_s3_image(bucket_name, image_key):\n",
    "    \"\"\"\n",
    "    Extrai todo o texto de uma imagem no S3 usando AWS Textract\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"🔍 Iniciando OCR da imagem: {image_key}\")\n",
    "        \n",
    "        # Executar OCR com Textract\n",
    "        response = textract_client.detect_document_text(\n",
    "            Document={\n",
    "                'S3Object': {\n",
    "                    'Bucket': bucket_name,\n",
    "                    'Name': image_key\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Processar resultados\n",
    "        extracted_text = \"\"\n",
    "        text_blocks = []\n",
    "        words = []\n",
    "        lines = []\n",
    "        \n",
    "        for block in response['Blocks']:\n",
    "            if block['BlockType'] == 'LINE':\n",
    "                line_text = block['Text']\n",
    "                extracted_text += line_text + \"\\n\"\n",
    "                lines.append({\n",
    "                    'text': line_text,\n",
    "                    'confidence': round(block['Confidence'], 2),\n",
    "                    'bounding_box': block['Geometry']['BoundingBox']\n",
    "                })\n",
    "            \n",
    "            elif block['BlockType'] == 'WORD':\n",
    "                words.append({\n",
    "                    'text': block['Text'],\n",
    "                    'confidence': round(block['Confidence'], 2),\n",
    "                    'bounding_box': block['Geometry']['BoundingBox']\n",
    "                })\n",
    "        \n",
    "        # Compilar resultados\n",
    "        result = {\n",
    "            'image_key': image_key,\n",
    "            'bucket_name': bucket_name,\n",
    "            'full_text': extracted_text.strip(),\n",
    "            'total_lines': len(lines),\n",
    "            'total_words': len(words),\n",
    "            'lines': lines,\n",
    "            'words': words,\n",
    "            'extraction_timestamp': datetime.now().isoformat(),\n",
    "            'aws_response_metadata': response.get('ResponseMetadata', {})\n",
    "        }\n",
    "        \n",
    "        # Estatísticas de confiança\n",
    "        if words:\n",
    "            confidences = [word['confidence'] for word in words]\n",
    "            result['confidence_stats'] = {\n",
    "                'average': round(sum(confidences) / len(confidences), 2),\n",
    "                'min': min(confidences),\n",
    "                'max': max(confidences)\n",
    "            }\n",
    "        \n",
    "        print(f\"📊 OCR CONCLUÍDO!\")\n",
    "        print(f\"   📝 Linhas de texto: {len(lines)}\")\n",
    "        print(f\"   🔤 Palavras detectadas: {len(words)}\")\n",
    "        print(f\"   🎯 Confiança média: {result.get('confidence_stats', {}).get('average', 'N/A')}%\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except ClientError as e:\n",
    "        print(f\"❌ Erro do AWS Textract: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro na extração de texto: {e}\")\n",
    "        return None\n",
    "\n",
    "def display_ocr_results(ocr_result):\n",
    "    \"\"\"Exibe resultados do OCR de forma organizada\"\"\"\n",
    "    if not ocr_result:\n",
    "        print(\"❌ Nenhum resultado de OCR para exibir\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"📄 RESULTADOS DO OCR (TEXTRACT)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"📸 Imagem: {ocr_result['image_key']}\")\n",
    "    print(f\"🕐 Processado em: {ocr_result['extraction_timestamp']}\")\n",
    "    print(f\"📊 Estatísticas:\")\n",
    "    print(f\"   • Linhas: {ocr_result['total_lines']}\")\n",
    "    print(f\"   • Palavras: {ocr_result['total_words']}\")\n",
    "    \n",
    "    if 'confidence_stats' in ocr_result:\n",
    "        stats = ocr_result['confidence_stats']\n",
    "        print(f\"   • Confiança: {stats['average']}% (min: {stats['min']}%, max: {stats['max']}%)\")\n",
    "    \n",
    "    print(f\"\\n📝 TEXTO EXTRAÍDO:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(ocr_result['full_text'])\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Mostrar linhas com baixa confiança (CORRIGIDO)\n",
    "    low_confidence_lines = [line for line in ocr_result['lines'] if line['confidence'] < 80]\n",
    "    if low_confidence_lines:\n",
    "        print(f\"\\n⚠️  LINHAS COM BAIXA CONFIANÇA (<80%):\")\n",
    "        for line in low_confidence_lines:\n",
    "            print(f\"   • '{line['text']}' (confiança: {line['confidence']}%)\")\n",
    "\n",
    "def save_ocr_results_to_s3(ocr_result, bucket_name):\n",
    "    \"\"\"Salva resultados do OCR no S3\"\"\"\n",
    "    try:\n",
    "        # Nome do arquivo de resultados\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        results_key = f\"ocr_results_{timestamp}.json\"\n",
    "        \n",
    "        # Salvar no S3\n",
    "        s3_client.put_object(\n",
    "            Bucket=bucket_name,\n",
    "            Key=results_key,\n",
    "            Body=json.dumps(ocr_result, indent=2, ensure_ascii=False),\n",
    "            ContentType='application/json',\n",
    "            Metadata={\n",
    "                'content-type': 'ocr-results',\n",
    "                'source-image': ocr_result['image_key']\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(f\"💾 Resultados salvos: s3://{bucket_name}/{results_key}\")\n",
    "        return results_key\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro ao salvar resultados: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"📦 Sistema de OCR configurado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7020cd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Executando OCR na sua imagem...\n",
      "🔍 Iniciando OCR da imagem: processed_Pasted image 20250608090919.png\n",
      "📊 OCR CONCLUÍDO!\n",
      "   📝 Linhas de texto: 36\n",
      "   🔤 Palavras detectadas: 143\n",
      "   🎯 Confiança média: 84.13%\n",
      "\n",
      "============================================================\n",
      "📄 RESULTADOS DO OCR (TEXTRACT)\n",
      "============================================================\n",
      "📸 Imagem: processed_Pasted image 20250608090919.png\n",
      "🕐 Processado em: 2025-06-10T16:09:13.888821\n",
      "📊 Estatísticas:\n",
      "   • Linhas: 36\n",
      "   • Palavras: 143\n",
      "   • Confiança: 84.13% (min: 7.03%, max: 99.94%)\n",
      "\n",
      "📝 TEXTO EXTRAÍDO:\n",
      "----------------------------------------\n",
      "FIAP MBA+\n",
      "FACE & TEXT EXTRACTION\n",
      "o setor de fraudes apontou que existem clientes que se queixaram de não contratar serviços\n",
      "específicos, como o crédito pessoal. Entretanto após o indicador de Detecção de vivacidade\n",
      "(liveness), desenvolvido na disciplina de Computer Vision, ter apresentado um percentual de\n",
      "vivacidade menor que 90% apontou a necessidade de uma nova validação do self da pessoa com o\n",
      "documento.\n",
      "REPUBLICA FEDERATIVA 00 BRASIL\n",
      "BR\n",
      "SECRETARIA NACIONA TRANSITO\n",
      "CARTERA NACIONAL DE HABULTACIO DRIVER LICENSE PERMISO DE CONDUCCION\n",
      "see\n",
      "det\n",
      "NOME SOCIAL TEST CENTOR DEZ\n",
      "16090389 SAO PALLOSS\n",
      "-\n",
      "Miss referencia\n",
      "Date\n",
      "- business\n",
      "26060022\n",
      "85 3691-7258\n",
      "JULHO 2022\n",
      "12/07/2022\n",
      "R$\n",
      "101.48\n",
      "503584349\n",
      "000000\n",
      "1195\n",
      "-\n",
      "10\n",
      "PA/DO TERTE HCM 5\n",
      "1. Extração da Face, Nome e CPF\n",
      "2. Comparação de faces (precisam ter\n",
      "3. Extração do Nome e Endereço. Nome\n",
      "mais do 90% de semelhança)\n",
      "precisa ser o mesmo da CNH.\n",
      "----------------------------------------\n",
      "\n",
      "⚠️  LINHAS COM BAIXA CONFIANÇA (<80%):\n",
      "   • 'CARTERA NACIONAL DE HABULTACIO DRIVER LICENSE PERMISO DE CONDUCCION' (confiança: 69.01%)\n",
      "   • 'see' (confiança: 7.03%)\n",
      "   • 'det' (confiança: 16.55%)\n",
      "   • 'NOME SOCIAL TEST CENTOR DEZ' (confiança: 59.88%)\n",
      "   • '16090389 SAO PALLOSS' (confiança: 31.92%)\n",
      "   • '-' (confiança: 25.78%)\n",
      "   • 'Miss referencia' (confiança: 36.08%)\n",
      "   • '- business' (confiança: 30.93%)\n",
      "   • '26060022' (confiança: 18.89%)\n",
      "   • '503584349' (confiança: 21.69%)\n",
      "   • '000000' (confiança: 25.43%)\n",
      "   • '1195' (confiança: 17.52%)\n",
      "   • '-' (confiança: 31.36%)\n",
      "   • '10' (confiança: 76.75%)\n",
      "   • 'PA/DO TERTE HCM 5' (confiança: 30.17%)\n",
      "💾 Resultados salvos: s3://staging-face-text/ocr_results_20250610_160913.json\n",
      "\n",
      "🎉 OCR CONCLUÍDO COM SUCESSO!\n",
      "📄 Todo o texto do seu infográfico foi extraído!\n"
     ]
    }
   ],
   "source": [
    "# Executar OCR na sua imagem processada\n",
    "bucket_name = 'staging-face-text'\n",
    "image_key = 'processed_Pasted image 20250608090919.png'\n",
    "\n",
    "print(\"🔍 Executando OCR na sua imagem...\")\n",
    "ocr_results = extract_text_from_s3_image(bucket_name, image_key)\n",
    "\n",
    "if ocr_results:\n",
    "    # Exibir resultados\n",
    "    display_ocr_results(ocr_results)\n",
    "    \n",
    "    # Salvar resultados no S3\n",
    "    results_key = save_ocr_results_to_s3(ocr_results, bucket_name)\n",
    "    \n",
    "    print(f\"\\n🎉 OCR CONCLUÍDO COM SUCESSO!\")\n",
    "    print(f\"📄 Todo o texto do seu infográfico foi extraído!\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Falha na extração de texto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e0b0382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cliente Rekognition reconfigurado!\n",
      "🚀 Executando detecção facial na sua imagem...\n",
      "👥 INICIANDO DETECÇÃO FACIAL\n",
      "==================================================\n",
      "🔍 Analisando faces na imagem: processed_Pasted image 20250608090919.png\n",
      "🎯 3 face(s) detectada(s) na imagem\n",
      "\n",
      "🎉 SUCESSO! 3 face(s) detectada(s)\n",
      "==================================================\n",
      "\n",
      "👤 FACE 1:\n",
      "   🎯 Confiança geral: 100.00%\n",
      "   📍 Posição: Left=0.498, Top=0.543\n",
      "   📏 Dimensões: Width=0.077, Height=0.172\n",
      "   🎂 Idade estimada: 18-22 anos\n",
      "   👫 Gênero: Female (confiança: 93.2%)\n",
      "   😊 Emoções detectadas:\n",
      "      • CALM: 94.6%\n",
      "      • HAPPY: 1.1%\n",
      "      • SURPRISED: 0.1%\n",
      "   📸 Qualidade da imagem:\n",
      "      • Brilho: 85.7\n",
      "      • Nitidez: 20.9\n",
      "\n",
      "👤 FACE 2:\n",
      "   🎯 Confiança geral: 99.99%\n",
      "   📍 Posição: Left=0.381, Top=0.583\n",
      "   📏 Dimensões: Width=0.045, Height=0.112\n",
      "   🎂 Idade estimada: 19-23 anos\n",
      "   👫 Gênero: Female (confiança: 99.2%)\n",
      "   😊 Emoções detectadas:\n",
      "      • HAPPY: 100.0%\n",
      "      • SURPRISED: 0.0%\n",
      "      • CALM: 0.0%\n",
      "   📸 Qualidade da imagem:\n",
      "      • Brilho: 90.4\n",
      "      • Nitidez: 7.6\n",
      "   👁️  Atributos detectados: Smile (97.9%)\n",
      "\n",
      "👤 FACE 3:\n",
      "   🎯 Confiança geral: 99.98%\n",
      "   📍 Posição: Left=0.121, Top=0.665\n",
      "   📏 Dimensões: Width=0.032, Height=0.079\n",
      "   🎂 Idade estimada: 19-25 anos\n",
      "   👫 Gênero: Female (confiança: 99.7%)\n",
      "   😊 Emoções detectadas:\n",
      "      • HAPPY: 100.0%\n",
      "      • SURPRISED: 0.0%\n",
      "      • CALM: 0.0%\n",
      "   📸 Qualidade da imagem:\n",
      "      • Brilho: 88.9\n",
      "      • Nitidez: 5.8\n",
      "   👁️  Atributos detectados: Smile (95.9%)\n",
      "\n",
      "📊 ESTATÍSTICAS GERAIS:\n",
      "   🎯 Confiança média: 99.99%\n",
      "   📈 Confiança máxima: 100.00%\n",
      "   📉 Confiança mínima: 99.98%\n"
     ]
    }
   ],
   "source": [
    "# Célula 9 CORRIGIDA: Sistema completo de detecção facial\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Reconfigurar cliente Rekognition (caso necessário)\n",
    "try:\n",
    "    rekognition_client = boto3.client('rekognition', region_name='us-east-1')\n",
    "    print(\"✅ Cliente Rekognition reconfigurado!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erro ao configurar Rekognition: {e}\")\n",
    "\n",
    "def detect_faces_in_image(bucket_name, image_key):\n",
    "    \"\"\"\n",
    "    Detecta faces em imagem armazenada no S3\n",
    "    \n",
    "    Args:\n",
    "        bucket_name (str): Nome do bucket S3\n",
    "        image_key (str): Chave/nome do arquivo no S3\n",
    "    \n",
    "    Returns:\n",
    "        list: Lista de detalhes das faces detectadas\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"🔍 Analisando faces na imagem: {image_key}\")\n",
    "        \n",
    "        response = rekognition_client.detect_faces(\n",
    "            Image={\n",
    "                'S3Object': {\n",
    "                    'Bucket': bucket_name,\n",
    "                    'Name': image_key\n",
    "                }\n",
    "            },\n",
    "            Attributes=['ALL']  # Retorna todos os atributos faciais\n",
    "        )\n",
    "        \n",
    "        faces = response['FaceDetails']\n",
    "        print(f\"🎯 {len(faces)} face(s) detectada(s) na imagem\")\n",
    "        \n",
    "        return faces\n",
    "        \n",
    "    except ClientError as e:\n",
    "        print(f\"❌ Erro do AWS Rekognition: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro geral na detecção: {e}\")\n",
    "        return []\n",
    "\n",
    "def analyze_face_details(face, face_number):\n",
    "    \"\"\"Analisa detalhes de uma face específica\"\"\"\n",
    "    print(f\"\\n👤 FACE {face_number}:\")\n",
    "    print(f\"   🎯 Confiança geral: {face['Confidence']:.2f}%\")\n",
    "    \n",
    "    # Posição da face\n",
    "    bbox = face['BoundingBox']\n",
    "    print(f\"   📍 Posição: Left={bbox['Left']:.3f}, Top={bbox['Top']:.3f}\")\n",
    "    print(f\"   📏 Dimensões: Width={bbox['Width']:.3f}, Height={bbox['Height']:.3f}\")\n",
    "    \n",
    "    # Idade estimada\n",
    "    if 'AgeRange' in face:\n",
    "        age = face['AgeRange']\n",
    "        print(f\"   🎂 Idade estimada: {age['Low']}-{age['High']} anos\")\n",
    "    \n",
    "    # Gênero\n",
    "    if 'Gender' in face:\n",
    "        gender = face['Gender']\n",
    "        print(f\"   👫 Gênero: {gender['Value']} (confiança: {gender['Confidence']:.1f}%)\")\n",
    "    \n",
    "    # Emoções\n",
    "    if 'Emotions' in face:\n",
    "        emotions = sorted(face['Emotions'], key=lambda x: x['Confidence'], reverse=True)\n",
    "        print(f\"   😊 Emoções detectadas:\")\n",
    "        for emotion in emotions[:3]:  # Top 3 emoções\n",
    "            print(f\"      • {emotion['Type']}: {emotion['Confidence']:.1f}%\")\n",
    "    \n",
    "    # Qualidade da imagem\n",
    "    if 'Quality' in face:\n",
    "        quality = face['Quality']\n",
    "        print(f\"   📸 Qualidade da imagem:\")\n",
    "        print(f\"      • Brilho: {quality['Brightness']:.1f}\")\n",
    "        print(f\"      • Nitidez: {quality['Sharpness']:.1f}\")\n",
    "    \n",
    "    # Atributos faciais\n",
    "    facial_attributes = ['Smile', 'Eyeglasses', 'Sunglasses', 'Beard', 'Mustache']\n",
    "    detected_attributes = []\n",
    "    \n",
    "    for attr in facial_attributes:\n",
    "        if attr in face and face[attr]['Value']:\n",
    "            confidence = face[attr]['Confidence']\n",
    "            detected_attributes.append(f\"{attr} ({confidence:.1f}%)\")\n",
    "    \n",
    "    if detected_attributes:\n",
    "        print(f\"   👁️  Atributos detectados: {', '.join(detected_attributes)}\")\n",
    "\n",
    "def run_face_detection():\n",
    "    \"\"\"Executa detecção facial completa na imagem processada\"\"\"\n",
    "    \n",
    "    bucket_name = 'staging-face-text'\n",
    "    image_key = 'processed_Pasted image 20250608090919.png'\n",
    "    \n",
    "    print(\"👥 INICIANDO DETECÇÃO FACIAL\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Executar detecção\n",
    "    faces = detect_faces_in_image(bucket_name, image_key)\n",
    "    \n",
    "    if faces:\n",
    "        print(f\"\\n🎉 SUCESSO! {len(faces)} face(s) detectada(s)\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Analisar cada face detectada\n",
    "        for i, face in enumerate(faces, 1):\n",
    "            analyze_face_details(face, i)\n",
    "        \n",
    "        # Estatísticas gerais\n",
    "        print(f\"\\n📊 ESTATÍSTICAS GERAIS:\")\n",
    "        confidences = [face['Confidence'] for face in faces]\n",
    "        print(f\"   🎯 Confiança média: {sum(confidences)/len(confidences):.2f}%\")\n",
    "        print(f\"   📈 Confiança máxima: {max(confidences):.2f}%\")\n",
    "        print(f\"   📉 Confiança mínima: {min(confidences):.2f}%\")\n",
    "        \n",
    "        return faces\n",
    "    else:\n",
    "        print(\"❌ Nenhuma face detectada na imagem\")\n",
    "        print(\"💡 Isso pode acontecer se:\")\n",
    "        print(\"   • As faces estão muito pequenas\")\n",
    "        print(\"   • A qualidade da imagem é baixa\")\n",
    "        print(\"   • As faces estão parcialmente ocultas\")\n",
    "        return []\n",
    "\n",
    "# Executar detecção facial\n",
    "print(\"🚀 Executando detecção facial na sua imagem...\")\n",
    "detected_faces = run_face_detection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
