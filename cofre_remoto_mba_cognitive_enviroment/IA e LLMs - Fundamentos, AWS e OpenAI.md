

An√°lise Abrangente de Ambientes Cognitivos e IA/LLMs

1. Vis√£o Geral e Contexto de IA/LLMs

Este briefing detalha os principais conceitos e ferramentas para o desenvolvimento e implanta√ß√£o de solu√ß√µes de Intelig√™ncia Artificial e Modelos de Linguagem de Grande Escala (LLMs), com foco nas plataformas da AWS e OpenAI. Aborda desde a base de dados e infraestrutura at√© modelos avan√ßados e frameworks como Langchain.

1.1. Crescimento e Acessibilidade da Tecnologia

O avan√ßo da IA √© impulsionado por fatores como a prolifera√ß√£o de¬†livros digitais, bibliotecas de fotos, dispositivos e IoT, e o¬†custo decrescente de armazenamento e processamento. Tecnologias como SoC, arquitetura ARM e SSDs mais acess√≠veis contribuem para essa democratiza√ß√£o. As¬†Big Techs¬†(Google, Meta) investem pesadamente em pesquisa e iniciativas Open Source (e.g., TensorFlow, Llama 3), enquanto provedores de cloud oferecem efici√™ncias de escala e experi√™ncia de usu√°rio.

1.2. Defini√ß√£o e Tipos de Modelos

‚Ä¢

Intelig√™ncia Artificial (IA):¬†Ampla √°rea da ci√™ncia da computa√ß√£o dedicada √† cria√ß√£o de m√°quinas que podem pensar, aprender e agir de forma inteligente.

‚Ä¢

Aprendizado de M√°quina (ML):¬†Subcampo da IA que permite que os sistemas aprendam com dados sem serem explicitamente programados.

‚Ä¢

Deep Learning (DL):¬†Subcampo do ML que utiliza redes neurais profundas para modelar padr√µes complexos em grandes conjuntos de dados.

1.3. Modelos de Linguagem de Grande Escala (LLMs)

LLMs como GPT (OpenAI), Bard (Google), Claude (Anthropic), Titan (AWS) e Llama (Meta) s√£o modelos de linguagem pr√©-treinados em vastos conjuntos de dados da internet, incluindo Wikipedia e livros. Eles se destacam pela capacidade de processar linguagem natural e gerar texto coerente e relevante.

‚Ä¢

Tokens:¬†A "granularidade m√≠nima de contagem para determinar tanto a entrada de dados quanto a sa√≠da." Um token n√£o √© necessariamente uma palavra inteira e pode variar em diferentes posicionamentos em uma frase.

‚ó¶

"1 token ~= 4 chars in English"

‚ó¶

"1 token ~= ¬æ words"

‚Ä¢

Janela de Contexto (Tokens):¬†"Quantidade de tokens que o modelo √© capaz de processar na entrada." Modelos com maiores janelas de contexto s√£o cruciais para t√©cnicas como RAG (Retrieval-Augmented Generation), que enviam "partes de conhecimento para o GPT utilizar como base."

‚Ä¢

Par√¢metros:¬†"Par√¢metros utilizados durante o treinamento de um determinado modelo. Quanto mais par√¢metros, mais robusto o modelo tende a ser." No entanto, "Para tarefas espec√≠ficas n√£o podemos deduzir que o n√∫mero de par√¢metros crescente em performance. Por isso a avalia√ß√£o humana se faz necess√°ria."

2. Plataformas de Cloud para IA e ML

As plataformas de cloud s√£o essenciais para o desenvolvimento de IA devido √† "Complexidade e Custo" e "Tempo de Desenvolvimento" envolvidos. Elas oferecem frameworks (TensorFlow, PyTorch, Scikit-Learn), APIs de cloud (Azure, AWS, IBM Cloud, Google Cloud, Hugging Face), e modelos pr√©-treinados, simplificando o processo.

2.1. AWS: Um Ecossistema Abrangente de Servi√ßos de IA

A AWS oferece uma vasta gama de servi√ßos de IA e ML, com foco em escalabilidade e facilidade de uso. Recomenda-se utilizar a regi√£o¬†us-east-1¬†por ser "a regi√£o mais barata dos servi√ßos da AWS". Para acesso aos servi√ßos, √© crucial criar um usu√°rio dedicado e obter chaves de acesso (ACCESS_ID¬†e¬†ACCESS_KEY), que "Nunca versione ou disponibilize... em reposit√≥rios, somente (em √∫ltimo caso quando somente voc√™ tem acesso) em reposit√≥rios privados."

2.1.1. Amazon SageMaker Canvas

Uma plataforma para "Treinamento e Implanta√ß√£o de Modelo no Sagemaker Studio". Permite o uso de "tecnologia AutoML da AWS" para construir modelos.

‚Ä¢

Fluxo de Trabalho:

1.

Carregar Dataset:¬†Suporta formatos tabular (CSV), imagens (PNG) e documentos (PDF).

2.

Revis√£o e Transforma√ß√£o de Dados:¬†Tipagem, tratamento de dados inv√°lidos.

3.

Feature Engineering:¬†Exemplos incluem "Convers√£o datas com horas e minutos para dia da semana, dia, hora e quarter," "Remo√ß√£o de atributos identificadores," e "Defini√ß√£o de intervalos para ser aplicado em idade."

4.

Treinamento do Modelo:¬†Ex: XGBoost para classifica√ß√£o log√≠stica bin√°ria. O "Standardt Build" busca "Precis√£o".

5.

Implanta√ß√£o (Infer√™ncia Serverless):¬†O SageMaker Canvas "somente permite a implanta√ß√£o de modelos via inst√¢ncias dedicadas de infer√™ncia" (em contraste com o SageMaker Studio, que suporta serverless).

2.1.2. Amazon Rekognition

Servi√ßo de vis√£o computacional para an√°lise de imagens e v√≠deos.

‚Ä¢

DetectLabels:¬†Detecta objetos e cenas em imagens, retornando r√≥tulos com "Confian√ßa m√≠nima necess√°ria para considerar um r√≥tulo."

‚Ä¢

DetectFaces:¬†Identifica faces e extrai atributos como "Idade, G√™nero, Pelos faciais, Sentimento, Abertura e fechamento dos olhos, Abertura e fechamento da boca, Posicionamento da face e elementos da face."

‚ó¶

Importante:¬†Para cen√°rios sens√≠veis, como aplica√ß√£o da lei, √© crucial "utilizar limiares de confian√ßa de 99% ou mais e empregar a revis√£o humana das previs√µes de compara√ß√£o facial para garantir que os direitos civis de uma pessoa n√£o sejam violados."

‚ó¶

Desafio 1 (Aula 1):¬†Criar um algoritmo para comparar duas faces, exigindo similaridade "acima de 90%" e proibindo "Face com oclus√£o (face parcialmente oculta), √ìculos de sol, Olhos fechados."

‚Ä¢

Moderation Labels:¬†Ajuda a "identificar conte√∫do potencialmente inadequado em imagens" (e.g., nudez, viol√™ncia, drogas). Os r√≥tulos s√£o hier√°rquicos (TaxonomyLevel).

‚Ä¢

Custom Labels:¬†"Uma ferramenta para treinar modelos de vis√£o computacional personalizados" para "reconhecer objetos ou padr√µes espec√≠ficos relevantes para o seu caso de uso."

‚ó¶

Classifica√ß√£o de Imagens:¬†Treinamento para classificar imagens em categorias (e.g., "truck," "car," "bus").

‚ó¶

Classifica√ß√£o de Objetos:¬†Treinamento para detectar e delimitar objetos em imagens, utilizando o padr√£o YOLO para anota√ß√µes.

2.1.3. Amazon Textract

"Servi√ßo especilizado em lidar com OCR (Optical Character Recognition), ou seja, √© capaz de identificar texto em imagens." Suporta "JPG e PNG" e "PDF" (at√© 5MB e 11 p√°ginas). Permite filtrar textos detectados com base na confian√ßa.

2.1.4. Amazon Comprehend

Servi√ßo de Processamento de Linguagem Natural (NLP) para an√°lise de texto.

‚Ä¢

Detec√ß√£o de Entidades:¬†Identifica entidades nomeadas (PESSOA, ORGANIZA√á√ÉO, etc.) em textos.

‚Ä¢

Modelo Customizado:¬†Permite "criar um modelo customizado treinamento textos correspondentes a uma determinada classe, por exemplo artigos e sua determinada categoria." Os dados devem estar em formato CSV, com a classe na primeira coluna e o texto na segunda. O Comprehend "separa os dados de treinamento e teste automaticamente."

‚ó¶

Requisitos de m√©tricas: "dados de precis√£o acima de 80% (isso varia com a especifica√ß√£o de cada projeto)." M√©tricas como Accuracy, Precision, Recall e F1 Score (Macro e Micro) e Hamming Loss s√£o avaliadas.

2.1.5. Amazon Polly

"Servi√ßo para converter texto em √°udio." Suporta diversos idiomas e a linguagem de marca√ß√£o SSML, que permite "adicionar uma pausa, enfatizar palavras, especificar outro idioma para palavras espec√≠ficas, usar pron√∫ncia fon√©tica" e controlar "volume, taxa de fala e tom," al√©m de efeitos especiais da Amazon como "sussurrando."

2.1.6. Amazon Transcribe

"Servi√ßo para transcrever em texto a partir de grava√ß√µes de voz. √â capaz de separar as pessoas que s√£o identificadas na grava√ß√£o."

2.1.7. Amazon Bedrock

"Servi√ßo da AWS que consolida diversos modelos de base de LLM de diferentes empresas, como por exemplo Meta, Anthropic, etc. al√©m dos modelos da pr√≥pria AWS." Oferece modelos generativos de texto/chat e imagem.

‚Ä¢

Playgrounds:¬†Ambientes para testar modelos, configura√ß√µes e payloads.

‚Ä¢

Modelos de Imagem:¬†Permitem configurar "Prompt negativo, Imagem de refer√™ncia, Tamanho, For√ßa do prompt, Propaga√ß√£o (ou seed)."

‚Ä¢

Gera√ß√£o de Texto:¬†Permite controlar a gera√ß√£o com par√¢metros como¬†max_gen_len,¬†temperature, e¬†top_p¬†(Top K define o n√∫mero de candidatos mais prov√°veis, Top P define a porcentagem dos candidatos mais prov√°veis).

2.1.8. AWS Lambda

"Um tipo de servi√ßo de computa√ß√£o serverless" que "permite que voc√™ execute c√≥digo sem precisar provisionar ou gerenciar servidores."

‚Ä¢

Caracter√≠sticas:¬†"Serverless," "Escalabilidade Autom√°tica," "Pagamento por Uso," "Integra√ß√£o com Servi√ßos AWS" (S3, DynamoDB, API Gateway, SNS, SQS, EventBridge).

‚Ä¢

Acionadores:¬†Pode ser iniciado por "eventos, como altera√ß√µes em dados no Amazon S3, atualiza√ß√µes em tabelas do Amazon DynamoDB, chamadas de API no Amazon API Gateway."

‚Ä¢

Deploy:¬†Pode ser feito localmente (empacotando depend√™ncias com¬†zip) ou via AWS CLI.

2.2. OpenAI

Pioneira em LLMs, oferece acesso √† s√©rie GPT de modelos.

‚Ä¢

Chave de API:¬†"Novos usu√°rios possuem 30 dias de acesso gratuito."

‚Ä¢

Modelos:

‚ó¶

GPT-4o:¬†"Modelo ‚Äúomni‚Äù com capacidades nativas de entrada e sa√≠da de texto, imagem e √°udio." (128.000 tokens)

‚ó¶

GPT-4 Turbo:¬†"Vers√£o otimizada do GPT-4, com maior janela de contexto e custo reduzido." (128.000 tokens)

‚ó¶

GPT-4:¬†"Mais capaz do que qualquer modelo GPT-3.5, capaz de realizar tarefas mais complexas e otimizado para conversa√ß√£o." (8.192 tokens)

‚ó¶

GPT-3.5 Turbo:¬†"Modelo GPT-3.5 mais capaz e otimizado para conversa√ß√£o a 1/10 do custo do text-davinci-003." (4.097 tokens, 16k vers√£o com 16.385 tokens)

‚Ä¢

DALL-E:¬†Modelo para gera√ß√£o de imagens a partir de texto.

‚Ä¢

Whisper:¬†Modelo para transcri√ß√£o de √°udio.

‚Ä¢

APIs:¬†Acesso aos modelos via API, usando a biblioteca¬†openai¬†e definindo¬†messages¬†com diferentes "pap√©is" (usu√°rio, sistema, assistente) para engenharia de prompt.

3. Frameworks e Ferramentas para Desenvolvimento de Aplica√ß√µes de IA

3.1. Boto3: AWS SDK Python

A biblioteca "oficial Python para todos os servi√ßos da AWS, incluindo os de Machine Learning." Permite usar credenciais armazenadas no AWS CLI para desenvolvimento local ou chaves diretamente no c√≥digo para servi√ßos externos como Google Colab. "Sempre utilize a documenta√ß√£o oficial."

3.2. Streamlit

"Uma biblioteca de c√≥digo aberto em Python que permite a cria√ß√£o r√°pida e f√°cil de aplicativos da web interativos para ci√™ncia de dados e aprendizado de m√°quina." Permite transformar scripts Python em apps web "com apenas algumas linhas de c√≥digo."

‚Ä¢

Interface:¬†Suporta Markdown para renderizar texto na aplica√ß√£o.

‚Ä¢

Interatividade:¬†Componentes como¬†spinner¬†(processamento pendente) e¬†success/error¬†(exibi√ß√£o de estados).

‚Ä¢

Secrets:¬†Armazenamento de "dados que n√£o precise ser exposto publicamente como chaves e endpoints" em arquivos¬†secrets.toml¬†dentro da pasta¬†.streamlit.

‚Ä¢

Depend√™ncias:¬†Utiliza bibliotecas como¬†Pillow¬†(recorte de imagem) e¬†Requests¬†(acesso a APIs externas). "Cravar o versionamento evita atualiza√ß√µes mais recentes que podem quebrar a compatibilidade do nosso projeto."

3.3. Langchain: LLM Framework

"Um framework relativamente novo que prop√µe a abstrair o uso de diferentes modelos de base de LLM ao integrar com cada uma das APIs e permitir que sejam constru√≠dos aplica√ß√µes n√£o dependentes de APIs pr√≥prias das plataformas e acrescentar novas camadas neste tipo de uso, tais como mem√≥ria, encadeamento e agentes."

‚Ä¢

Prompt Template:¬†Permite padronizar prompts, substituindo partes din√¢micas por vari√°veis. Exemplo: analisar avalia√ß√µes de clientes.

‚Ä¢

Mem√≥ria e Contexto:¬†Adiciona contexto √†s intera√ß√µes com LLMs, similar ao contexto de conversa do ChatGPT.

‚ó¶

Buffer de Conversa:¬†Mant√©m o hist√≥rico da conversa para contextualiza√ß√£o.

‚ó¶

Buffer de Conversa com Janela:¬†Limita o contexto a uma janela de intera√ß√µes.

‚ó¶

Buffer de Conversa com Tokens:¬†Limita o contexto por n√∫mero de tokens.

‚ó¶

Sumariza√ß√£o:¬†Utiliza o pr√≥prio LLM para resumir a mem√≥ria, otimizando o uso de tokens.

‚Ä¢

Dados Externos (Retrieval-Augmented Generation - RAG):¬†Permite adicionar "conhecimento especializado da qual n√£o foi originalmente treinado" aos LLMs.

‚ó¶

Fine-tuning:¬†Treinar o modelo com mais exemplos de prompt e resposta (custoso).

‚ó¶

Embeddings:¬†Mapear documentos para representa√ß√µes vetoriais que permitem uma "pesquisa inicial para ent√£o levar aos LLMs contexto relevante para uma resposta ser elaborada."¬†*¬†Loader:¬†Ferramentas para carregar diferentes tipos de documentos (CSVLoader, PDFLoader).¬†*¬†Vector Store (Ex: FAISS):¬†Armazenamento de embeddings com √≠ndices para busca por similaridade.¬†* Permite "citar as fontes dos documentos utilizados" para garantir a origem da resposta.

‚Ä¢

Agentes:¬†Permite "cria√ß√£o de agentes utilizando os LLM como formas de criar uma planejamento, escolha de a√ß√£o e refino das respostas obtidas." Agentes podem suprir defici√™ncias dos LLMs ou conectar com outros sistemas (e.g., Agente de Matem√°tica, Wikipedia). Permite criar ferramentas customizadas que consomem APIs externas.

4. Exemplos e Desafios Pr√°ticos

Os materiais fornecem diversos exemplos pr√°ticos e desafios, ilustrando a aplica√ß√£o dos servi√ßos e frameworks.

‚Ä¢

Detec√ß√£o de Face para Documentos (Streamlit):¬†Valida√ß√µes de face como aus√™ncia de oclus√£o, √≥culos de sol, olhos fechados, e similaridade acima de 90%.

‚Ä¢

Classifica√ß√£o de Planta√ß√µes (Rekognition Custom Labels):¬†Desafio para "Criar um modelo para classificar diferentes tipos de planta√ß√µes (considere no m√≠nimo 3 classes). Busque alcan√ßar valores de precis√£o, recall e average precision maiores do que 90%."

‚Ä¢

An√°lise de Avalia√ß√µes de Clientes (Langchain + LLM):

‚ó¶

Desafio 1 (Aula 4): "Revise as avalia√ß√µes da Amazon utilizando LLM e extraia as seguintes informa√ß√µes: resumo em at√© 300 caracteres em tom calmo, an√°lise de sentimento (positivo, negativou ou neutro) e uma pontua√ß√£o de -10 at√© +10 em rela√ß√£o ao sentimento detectado."

‚ó¶

Exemplo de sintetiza√ß√£o de reclama√ß√µes para padronizar an√°lises e remover palavras irrelevantes.

‚Ä¢

Intera√ß√£o com Conhecimento Externo (Langchain):¬†Exemplos de uso de embeddings para buscar informa√ß√µes em datasets CSV (avalia√ß√µes do Mercado Livre) e PDF, e usar o LLM para responder com base nesse contexto.

5. Recomenda√ß√µes e Melhores Pr√°ticas

‚Ä¢

Seguran√ßa de Credenciais:¬†"Nunca versione ou disponibilize as chaves de acesso em reposit√≥rios, somente (em √∫ltimo caso quando somente voc√™ tem acesso) em reposit√≥rios privados." Utilizar vari√°veis de ambiente ou servi√ßos de secrets (como no Streamlit) √© fundamental.

‚Ä¢

Documenta√ß√£o Oficial:¬†"Sempre utilize a documenta√ß√£o oficial" para SDKs e APIs, pois os modelos e servi√ßos podem ser atualizados ou descontinuados.

‚Ä¢

Versionamento de Depend√™ncias:¬†"Cravar o versionamento evita atualiza√ß√µes mais recentes que podem quebrar a compatibilidade do nosso projeto."

‚Ä¢

Revis√£o Humana:¬†Para cen√°rios cr√≠ticos que impactam direitos civis, "a decis√£o de agir deve ser tomada por uma pessoa devidamente treinada com base em sua an√°lise independente da evid√™ncia de identifica√ß√£o."

‚Ä¢

Otimiza√ß√£o de Custos:

‚ó¶

Utilizar a regi√£o¬†us-east-1¬†na AWS.

‚ó¶

A execu√ß√£o de detec√ß√£o por¬†Job¬†no Amazon Comprehend "tem custo muito menor que a em tempo real."

‚ó¶

Avaliar os limites m√°ximos de gastos para aplica√ß√µes em produ√ß√£o com servi√ßos de LLM.

‚ó¶

T√©cnicas como sumariza√ß√£o e embeddings em Langchain ajudam a diminuir o n√∫mero de tokens enviados aos LLMs, reduzindo custos.

6. Considera√ß√µes Finais

O campo da IA e LLMs est√° em constante evolu√ß√£o, com o lan√ßamento de novos modelos e t√©cnicas a cada m√™s. A compreens√£o dos conceitos fundamentais, a familiaridade com as principais plataformas de cloud (AWS, OpenAI) e o dom√≠nio de frameworks como Langchain s√£o cruciais para o desenvolvimento de solu√ß√µes inteligentes e escal√°veis. A √™nfase na acessibilidade, na otimiza√ß√£o de custos e na seguran√ßa √© igualmente importante para a implanta√ß√£o bem-sucedida dessas tecnologias.

## Chat

tune

ü©∫

# Cognitive Enviroments

15 fontes

Os materiais fornecem uma introdu√ß√£o abrangente √†s¬†**plataformas cognitivas**, com foco em¬†**Intelig√™ncia Artificial (IA)**¬†e¬†**Machine Learning (ML)**. Eles exploram a¬†**utiliza√ß√£o de plataformas**¬†para processamento de dados e discorrem sobre a¬†**anatomia de um produto de IA**, abordando desde a coleta e organiza√ß√£o de dados at√© a constru√ß√£o e implanta√ß√£o de modelos. Os documentos detalham a funcionalidade e aplica√ß√£o de servi√ßos espec√≠ficos da¬†**Amazon Web Services (AWS)**, como¬†**SageMaker Canvas**¬†para constru√ß√£o de modelos,¬†**Amazon Textract**¬†para reconhecimento de texto em imagens,¬†**Amazon Rekognition**¬†para an√°lise e reconhecimento facial/de objetos, e¬†**Amazon Comprehend**¬†para processamento de linguagem natural, incluindo detec√ß√£o de entidades e an√°lise de sentimentos. Al√©m disso, as fontes aprofundam-se nos¬†**Modelos de Linguagem de Grande Escala (LLMs)**, como¬†**GPT, Llama, Claude**¬†e¬†**Titan**, discutindo suas caracter√≠sticas, acesso via¬†**AWS Bedrock**¬†e¬†**OpenAI API**, e t√©cnicas como¬†**Prompt Engineering**¬†e¬†**Langchain**¬†para otimizar intera√ß√µes e integrar dados externos, incluindo o uso de agentes para tarefas complexas.

keepSalvar notacopy_all

docsAdicionar notaaudio_magic_eraserResumo em √ÅudioflowchartMapa mental

15 fontes

send

chevron_right

Descreva o papel do Langchain no uso de LLMs e suas camadas.Explique como a AWS Lambda contribui para a escalabilidade de aplica√ß√µes de IA.Compare as funcionalidades do Amazon Rekognition e do Amazon Textract.

## Est√∫dio

dock_to_left

## Resumo em √Åudio

info

üéâCrie um Resumo em √Åudio em mais idiomas![Saiba mais](https://support.google.com/notebooklm/answer/16212820?ref_topic=16164070&sjid=3352195109469844277-NC)

speaker

Conversa aprofundada

Dois apresentadores

Personalizar

Gerar

## Notas

more_vert

addAdicionar nota

schoolGuia de estudosummarize_autoDocumento de resumo

speaker_notesPerguntas frequentestimelineLinha do tempo

drive_documentPlataformas Cognitivas, IA e AWS: Guia AbrangenteOs materiais fornecem uma introdu√ß√£o abrangente √†s plataformas cognitivas, com foco em Intelig√™ncia Artificial (IA) e Machine Learning (ML). Eles exploram a utiliza√ß√£o de plataformas para processamento de dados e discorrem sobre a anatomia de um produto de IA, abordando desde a coleta e organiza√ß√£o de dados at√© a constru√ß√£o e implanta√ß√£o de modelos. Os documentos detalham a funcionalidade e aplica√ß√£o de servi√ßos espec√≠ficos da Amazon Web Services (AWS), como SageMaker Canvas para constru√ß√£o de modelos, Amazon Textract para reconhecimento de texto em imagens, Amazon Rekognition para an√°lise e reconhecimento facial/de objetos, e Amazon Comprehend para processamento de linguagem natural, incluindo detec√ß√£o de entidades e an√°lise de sentimentos. Al√©m disso, as fontes aprofundam-se nos Modelos de Linguagem de Grande Escala (LLMs), como GPT, Llama, Claude e Titan, discutindo suas caracter√≠sticas, acesso via AWS Bedrock e OpenAI API, e t√©cnicas como Prompt Engineering e Langchain para otimizar intera√ß√µes e integrar dados externos, incluindo o uso de agentes para tarefas complexas.

drive_documentIA e LLMs: Fundamentos, AWS e OpenAIAn√°lise Abrangente de Ambientes Cognitivos e IA/LLMs 1. Vis√£o Geral e Contexto de IA/LLMs Este briefing detalha os principais conceitos e ferramentas para o desenvolvimento e implanta√ß√£o de solu√ß√µes de Intelig√™ncia Artificial e Modelos de Linguagem de Grande Escala (LLMs), com foco nas plataformas da AWS e OpenAI. Aborda desde a base de dados e infraestrutura at√© modelos avan√ßados e frameworks como Langchain. 1.1. Crescimento e Acessibilidade da Tecnologia O avan√ßo da IA √© impulsionado por fatores como a prolifera√ß√£o de livros digitais, bibliotecas de fotos, dispositivos e IoT, e o custo decrescente de armazenamento e processamento. Tecnologias como SoC, arquitetura ARM e SSDs mais acess√≠veis contribuem para essa democratiza√ß√£o. As Big Techs (Google, Meta) investem pesadamente em pesquisa e iniciativas Open Source (e.g., TensorFlow, Llama 3), enquanto provedores de cloud oferecem efici√™ncias de escala e experi√™ncia de usu√°rio. 1.2. Defini√ß√£o e Tipos de Modelos Intelig√™ncia Artificial (IA): Ampla √°rea da ci√™ncia da computa√ß√£o dedicada √† cria√ß√£o de m√°quinas que podem pensar, aprender e agir de forma inteligente. Aprendizado de M√°quina (ML): Subcampo da IA que permite que os sistemas aprendam com dados sem serem explicitamente programados. Deep Learning (DL): Subcampo do ML que utiliza redes neurais profundas para modelar padr√µes complexos em grandes conjuntos de dados. 1.3. Modelos de Linguagem de Grande Escala (LLMs) LLMs como GPT (OpenAI), Bard (Google), Claude (Anthropic), Titan (AWS) e Llama (Meta) s√£o modelos de linguagem pr√©-treinados em vastos conjuntos de dados da internet, incluindo Wikipedia e livros. Eles se destacam pela capacidade de processar linguagem natural e gerar texto coerente e relevante. Tokens: A "granularidade m√≠nima de contagem para determinar tanto a entrada de dados quanto a sa√≠da." Um token n√£o √© necessariamente uma palavra inteira e pode variar em diferentes posicionamentos em uma frase. "1 token ~= 4 chars in English" "1 token ~= ¬æ words" Janela de Contexto (Tokens): "Quantidade de tokens que o modelo √© capaz de processar na entrada." Modelos com maiores janelas de contexto s√£o cruciais para t√©cnicas como RAG (Retrieval-Augmented Generation), que enviam "partes de conhecimento para o GPT utilizar como base." Par√¢metros: "Par√¢metros utilizados durante o treinamento de um determinado modelo. Quanto mais par√¢metros, mais robusto o modelo tende a ser." No entanto, "Para tarefas espec√≠ficas n√£o podemos deduzir que o n√∫mero de par√¢metros crescente em performance. Por isso a avalia√ß√£o humana se faz necess√°ria." 2. Plataformas de Cloud para IA e ML As plataformas de cloud s√£o essenciais para o desenvolvimento de IA devido √† "Complexidade e Custo" e "Tempo de Desenvolvimento" envolvidos. Elas oferecem frameworks (TensorFlow, PyTorch, Scikit-Learn), APIs de cloud (Azure, AWS, IBM Cloud, Google Cloud, Hugging Face), e modelos pr√©-treinados, simplificando o processo. 2.1. AWS: Um Ecossistema Abrangente de Servi√ßos de IA A AWS oferece uma vasta gama de servi√ßos de IA e ML, com foco em escalabilidade e facilidade de uso. Recomenda-se utilizar a regi√£o us-east-1 por ser "a regi√£o mais barata dos servi√ßos da AWS". Para acesso aos servi√ßos, √© crucial criar um usu√°rio dedicado e obter chaves de acesso (ACCESS_ID e ACCESS_KEY), que "Nunca versione ou disponibilize... em reposit√≥rios, somente (em √∫ltimo caso quando somente voc√™ tem acesso) em reposit√≥rios privados." 2.1.1. Amazon SageMaker Canvas Uma plataforma para "Treinamento e Implanta√ß√£o de Modelo no Sagemaker Studio". Permite o uso de "tecnologia AutoML da AWS" para construir modelos. Fluxo de Trabalho: Carregar Dataset: Suporta formatos tabular (CSV), imagens (PNG) e documentos (PDF). Revis√£o e Transforma√ß√£o de Dados: Tipagem, tratamento de dados inv√°lidos. Feature Engineering: Exemplos incluem "Convers√£o datas com horas e minutos para dia da semana, dia, hora e quarter," "Remo√ß√£o de atributos identificadores," e "Defini√ß√£o de intervalos para ser aplicado em idade." Treinamento do Modelo: Ex: XGBoost para classifica√ß√£o log√≠stica bin√°ria. O "Standardt Build" busca "Precis√£o". Implanta√ß√£o (Infer√™ncia Serverless): O SageMaker Canvas "somente permite a implanta√ß√£o de modelos via inst√¢ncias dedicadas de infer√™ncia" (em contraste com o SageMaker Studio, que suporta serverless). 2.1.2. Amazon Rekognition Servi√ßo de vis√£o computacional para an√°lise de imagens e v√≠deos. DetectLabels: Detecta objetos e cenas em imagens, retornando r√≥tulos com "Confian√ßa m√≠nima necess√°ria para considerar um r√≥tulo." DetectFaces: Identifica faces e extrai atributos como "Idade, G√™nero, Pelos faciais, Sentimento, Abertura e fechamento dos olhos, Abertura e fechamento da boca, Posicionamento da face e elementos da face." Importante: Para cen√°rios sens√≠veis, como aplica√ß√£o da lei, √© crucial "utilizar limiares de confian√ßa de 99% ou mais e empregar a revis√£o humana das previs√µes de compara√ß√£o facial para garantir que os direitos civis de uma pessoa n√£o sejam violados." Desafio 1 (Aula 1): Criar um algoritmo para comparar duas faces, exigindo similaridade "acima de 90%" e proibindo "Face com oclus√£o (face parcialmente oculta), √ìculos de sol, Olhos fechados." Moderation Labels: Ajuda a "identificar conte√∫do potencialmente inadequado em imagens" (e.g., nudez, viol√™ncia, drogas). Os r√≥tulos s√£o hier√°rquicos (TaxonomyLevel). Custom Labels: "Uma ferramenta para treinar modelos de vis√£o computacional personalizados" para "reconhecer objetos ou padr√µes espec√≠ficos relevantes para o seu caso de uso." Classifica√ß√£o de Imagens: Treinamento para classificar imagens em categorias (e.g., "truck," "car," "bus"). Classifica√ß√£o de Objetos: Treinamento para detectar e delimitar objetos em imagens, utilizando o padr√£o YOLO para anota√ß√µes. 2.1.3. Amazon Textract "Servi√ßo especilizado em lidar com OCR (Optical Character Recognition), ou seja, √© capaz de identificar texto em imagens." Suporta "JPG e PNG" e "PDF" (at√© 5MB e 11 p√°ginas). Permite filtrar textos detectados com base na confian√ßa. 2.1.4. Amazon Comprehend Servi√ßo de Processamento de Linguagem Natural (NLP) para an√°lise de texto. Detec√ß√£o de Entidades: Identifica entidades nomeadas (PESSOA, ORGANIZA√á√ÉO, etc.) em textos. Modelo Customizado: Permite "criar um modelo customizado treinamento textos correspondentes a uma determinada classe, por exemplo artigos e sua determinada categoria." Os dados devem estar em formato CSV, com a classe na primeira coluna e o texto na segunda. O Comprehend "separa os dados de treinamento e teste automaticamente." Requisitos de m√©tricas: "dados de precis√£o acima de 80% (isso varia com a especifica√ß√£o de cada projeto)." M√©tricas como Accuracy, Precision, Recall e F1 Score (Macro e Micro) e Hamming Loss s√£o avaliadas. 2.1.5. Amazon Polly "Servi√ßo para converter texto em √°udio." Suporta diversos idiomas e a linguagem de marca√ß√£o SSML, que permite "adicionar uma pausa, enfatizar palavras, especificar outro idioma para palavras espec√≠ficas, usar pron√∫ncia fon√©tica" e controlar "volume, taxa de fala e tom," al√©m de efeitos especiais da Amazon como "sussurrando." 2.1.6. Amazon Transcribe "Servi√ßo para transcrever em texto a partir de grava√ß√µes de voz. √â capaz de separar as pessoas que s√£o identificadas na grava√ß√£o." 2.1.7. Amazon Bedrock "Servi√ßo da AWS que consolida diversos modelos de base de LLM de diferentes empresas, como por exemplo Meta, Anthropic, etc. al√©m dos modelos da pr√≥pria AWS." Oferece modelos generativos de texto/chat e imagem. Playgrounds: Ambientes para testar modelos, configura√ß√µes e payloads. Modelos de Imagem: Permitem configurar "Prompt negativo, Imagem de refer√™ncia, Tamanho, For√ßa do prompt, Propaga√ß√£o (ou seed)." Gera√ß√£o de Texto: Permite controlar a gera√ß√£o com par√¢metros como max_gen_len, temperature, e top_p (Top K define o n√∫mero de candidatos mais prov√°veis, Top P define a porcentagem dos candidatos mais prov√°veis). 2.1.8. AWS Lambda "Um tipo de servi√ßo de computa√ß√£o serverless" que "permite que voc√™ execute c√≥digo sem precisar provisionar ou gerenciar servidores." Caracter√≠sticas: "Serverless," "Escalabilidade Autom√°tica," "Pagamento por Uso," "Integra√ß√£o com Servi√ßos AWS" (S3, DynamoDB, API Gateway, SNS, SQS, EventBridge). Acionadores: Pode ser iniciado por "eventos, como altera√ß√µes em dados no Amazon S3, atualiza√ß√µes em tabelas do Amazon DynamoDB, chamadas de API no Amazon API Gateway." Deploy: Pode ser feito localmente (empacotando depend√™ncias com zip) ou via AWS CLI. 2.2. OpenAI Pioneira em LLMs, oferece acesso √† s√©rie GPT de modelos. Chave de API: "Novos usu√°rios possuem 30 dias de acesso gratuito." Modelos: GPT-4o: "Modelo ‚Äúomni‚Äù com capacidades nativas de entrada e sa√≠da de texto, imagem e √°udio." (128.000 tokens) GPT-4 Turbo: "Vers√£o otimizada do GPT-4, com maior janela de contexto e custo reduzido." (128.000 tokens) GPT-4: "Mais capaz do que qualquer modelo GPT-3.5, capaz de realizar tarefas mais complexas e otimizado para conversa√ß√£o." (8.192 tokens) GPT-3.5 Turbo: "Modelo GPT-3.5 mais capaz e otimizado para conversa√ß√£o a 1/10 do custo do text-davinci-003." (4.097 tokens, 16k vers√£o com 16.385 tokens) DALL-E: Modelo para gera√ß√£o de imagens a partir de texto. Whisper: Modelo para transcri√ß√£o de √°udio. APIs: Acesso aos modelos via API, usando a biblioteca openai e definindo messages com diferentes "pap√©is" (usu√°rio, sistema, assistente) para engenharia de prompt. 3. Frameworks e Ferramentas para Desenvolvimento de Aplica√ß√µes de IA 3.1. Boto3: AWS SDK Python A biblioteca "oficial Python para todos os servi√ßos da AWS, incluindo os de Machine Learning." Permite usar credenciais armazenadas no AWS CLI para desenvolvimento local ou chaves diretamente no c√≥digo para servi√ßos externos como Google Colab. "Sempre utilize a documenta√ß√£o oficial." 3.2. Streamlit "Uma biblioteca de c√≥digo aberto em Python que permite a cria√ß√£o r√°pida e f√°cil de aplicativos da web interativos para ci√™ncia de dados e aprendizado de m√°quina." Permite transformar scripts Python em apps web "com apenas algumas linhas de c√≥digo." Interface: Suporta Markdown para renderizar texto na aplica√ß√£o. Interatividade: Componentes como spinner (processamento pendente) e success/error (exibi√ß√£o de estados). Secrets: Armazenamento de "dados que n√£o precise ser exposto publicamente como chaves e endpoints" em arquivos secrets.toml dentro da pasta .streamlit. Depend√™ncias: Utiliza bibliotecas como Pillow (recorte de imagem) e Requests (acesso a APIs externas). "Cravar o versionamento evita atualiza√ß√µes mais recentes que podem quebrar a compatibilidade do nosso projeto." 3.3. Langchain: LLM Framework "Um framework relativamente novo que prop√µe a abstrair o uso de diferentes modelos de base de LLM ao integrar com cada uma das APIs e permitir que sejam constru√≠dos aplica√ß√µes n√£o dependentes de APIs pr√≥prias das plataformas e acrescentar novas camadas neste tipo de uso, tais como mem√≥ria, encadeamento e agentes." Prompt Template: Permite padronizar prompts, substituindo partes din√¢micas por vari√°veis. Exemplo: analisar avalia√ß√µes de clientes. Mem√≥ria e Contexto: Adiciona contexto √†s intera√ß√µes com LLMs, similar ao contexto de conversa do ChatGPT. Buffer de Conversa: Mant√©m o hist√≥rico da conversa para contextualiza√ß√£o. Buffer de Conversa com Janela: Limita o contexto a uma janela de intera√ß√µes. Buffer de Conversa com Tokens: Limita o contexto por n√∫mero de tokens. Sumariza√ß√£o: Utiliza o pr√≥prio LLM para resumir a mem√≥ria, otimizando o uso de tokens. Dados Externos (Retrieval-Augmented Generation - RAG): Permite adicionar "conhecimento especializado da qual n√£o foi originalmente treinado" aos LLMs. Fine-tuning: Treinar o modelo com mais exemplos de prompt e resposta (custoso). Embeddings: Mapear documentos para representa√ß√µes vetoriais que permitem uma "pesquisa inicial para ent√£o levar aos LLMs contexto relevante para uma resposta ser elaborada." Loader: Ferramentas para carregar diferentes tipos de documentos (CSVLoader, PDFLoader). Vector Store (Ex: FAISS): Armazenamento de embeddings com √≠ndices para busca por similaridade. Permite "citar as fontes dos documentos utilizados" para garantir a origem da resposta. Agentes: Permite "cria√ß√£o de agentes utilizando os LLM como formas de criar uma planejamento, escolha de a√ß√£o e refino das respostas obtidas." Agentes podem suprir defici√™ncias dos LLMs ou conectar com outros sistemas (e.g., Agente de Matem√°tica, Wikipedia). Permite criar ferramentas customizadas que consomem APIs externas. 4. Exemplos e Desafios Pr√°ticos Os materiais fornecem diversos exemplos pr√°ticos e desafios, ilustrando a aplica√ß√£o dos servi√ßos e frameworks. Detec√ß√£o de Face para Documentos (Streamlit): Valida√ß√µes de face como aus√™ncia de oclus√£o, √≥culos de sol, olhos fechados, e similaridade acima de 90%. Classifica√ß√£o de Planta√ß√µes (Rekognition Custom Labels): Desafio para "Criar um modelo para classificar diferentes tipos de planta√ß√µes (considere no m√≠nimo 3 classes). Busque alcan√ßar valores de precis√£o, recall e average precision maiores do que 90%." An√°lise de Avalia√ß√µes de Clientes (Langchain + LLM): Desafio 1 (Aula 4): "Revise as avalia√ß√µes da Amazon utilizando LLM e extraia as seguintes informa√ß√µes: resumo em at√© 300 caracteres em tom calmo, an√°lise de sentimento (positivo, negativou ou neutro) e uma pontua√ß√£o de -10 at√© +10 em rela√ß√£o ao sentimento detectado." Exemplo de sintetiza√ß√£o de reclama√ß√µes para padronizar an√°lises e remover palavras irrelevantes. Intera√ß√£o com Conhecimento Externo (Langchain): Exemplos de uso de embeddings para buscar informa√ß√µes em datasets CSV (avalia√ß√µes do Mercado Livre) e PDF, e usar o LLM para responder com base nesse contexto. 5. Recomenda√ß√µes e Melhores Pr√°ticas Seguran√ßa de Credenciais: "Nunca versione ou disponibilize as chaves de acesso em reposit√≥rios, somente (em √∫ltimo caso quando somente voc√™ tem acesso) em reposit√≥rios privados." Utilizar vari√°veis de ambiente ou servi√ßos de secrets (como no Streamlit) √© fundamental. Documenta√ß√£o Oficial: "Sempre utilize a documenta√ß√£o oficial" para SDKs e APIs, pois os modelos e servi√ßos podem ser atualizados ou descontinuados. Versionamento de Depend√™ncias: "Cravar o versionamento evita atualiza√ß√µes mais recentes que podem quebrar a compatibilidade do nosso projeto." Revis√£o Humana: Para cen√°rios cr√≠ticos que impactam direitos civis, "a decis√£o de agir deve ser tomada por uma pessoa devidamente treinada com base em sua an√°lise independente da evid√™ncia de identifica√ß√£o." Otimiza√ß√£o de Custos: Utilizar a regi√£o us-east-1 na AWS. A execu√ß√£o de detec√ß√£o por Job no Amazon Comprehend "tem custo muito menor que a em tempo real." Avaliar os limites m√°ximos de gastos para aplica√ß√µes em produ√ß√£o com servi√ßos de LLM. T√©cnicas como sumariza√ß√£o e embeddings em Langchain ajudam a diminuir o n√∫mero de tokens enviados aos LLMs, reduzindo custos. 6. Considera√ß√µes Finais O campo da IA e LLMs est√° em constante evolu√ß√£o, com o lan√ßamento de novos modelos e t√©cnicas a cada m√™s. A compreens√£o dos conceitos fundamentais, a familiaridade com as principais plataformas de cloud (AWS, OpenAI) e o dom√≠nio de frameworks como Langchain s√£o cruciais para o desenvolvimento de solu√ß√µes inteligentes e escal√°veis. A √™nfase na acessibilidade, na otimiza√ß√£o de custos e na seguran√ßa √© igualmente importante para a implanta√ß√£o bem-sucedida dessas tecnologias.